{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "from IPython.display import HTML\n",
    "# import itertools\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t\t\tfont-weight: bolder;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Funciones y variables globales</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archivo conteos y agrupaciones a doc. original\n",
    "# wb_original_results = './Cambios_aplicados/wb_original_results.xlsx'\n",
    "wb_final_results = './Cambios_aplicados/wb_final_results.xlsx'\n",
    "\n",
    "# wb libro regs únicos \n",
    "wb_regs_unicos = './Cambios_aplicados/wb_regs_unicos.xlsx'\n",
    "\n",
    "# libro a analizar\n",
    "# variables files\n",
    "file_to_analize = './Sitios SEMS.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funciones globales\n",
    "\n",
    "def save_df_changes(df_object, file_name='Libro_cambios_aplicados'):\n",
    "  \"\"\"\n",
    "  Save workbooks in the default path with xlsx extention\n",
    "  \n",
    "\tArgs:\n",
    "\t\t\tdf_object (_type_): dataframe to save as file\n",
    "\t\t\tfile_name (str, optional): filename NO extention\n",
    "\t\"\"\"\n",
    "  try:\n",
    "    df_object.to_excel(f'./Cambios_aplicados/{file_name}.xlsx', index=None)\n",
    "    print(f'Se ha exportado el libro: {file_name}.xlsx\\nRuta del archivo: \"Cambios_aplicados -> {file_name}.xlsx\"')\n",
    "  except PermissionError:\n",
    "    print(\"el libro no se pudo exportar, debido a que el libro exportado anteriormente esta abierto, se debe cerrar.\")\n",
    "\n",
    "def get_acronym(state_name):\n",
    "  \"\"\"\n",
    "  get the acronym from the mexican state\n",
    "  \"\"\"\n",
    "  tmp_res = None\n",
    "  state_name = state_name.upper()\n",
    "  try:\n",
    "    stts_mexico = {\n",
    "      'AGUASCALIENTES' : 'AGS.', 'BAJA CALIFORNIA' : 'B.C.', 'BAJA CALIFORNIA SUR' : 'B.C.S.', 'CAMPECHE' : 'CAMP.', 'COAHUILA DE ZARAGOZA' : 'COAH.', 'COLIMA' : 'COL.', 'CHIAPAS' : 'CHIS.', 'CHIHUAHUA' : 'CHIH.', 'CIUDAD DE MÉXICO' : 'C.D.M.X.', 'DURANGO' : 'DGO.', 'GUANAJUATO' : 'GTO.', 'GUERRERO' : 'GRO.', 'HIDALGO' : 'HGO.', 'JALISCO' : 'JAL.', 'MÉXICO' : 'MÉX.', 'MICHOACÁN DE OCAMPO' : 'MICH.', 'MORELOS' : 'MOR.', 'NAYARIT' : 'NAY.', 'NUEVO LEÓN' : 'N.L.', 'OAXACA' : 'OAX.', 'PUEBLA' : 'PUE.', 'QUERÉTARO' : 'QRO.', 'QUINTANA ROO' : 'Q. ROO.', 'SAN LUIS POTOSÍ' : 'S.L.P.', 'SINALOA' : 'SIN.', 'SONORA' : 'SON.', 'TABASCO' : 'TAB.', 'TAMAULIPAS' : 'TAMPS.', 'TLAXCALA' : 'TLAX.', 'VERACRUZ DE IGNACIO DE LA LLAVE' : 'VER.', 'YUCATÁN' : 'YUC.', 'ZACATECAS' : 'ZAC.'}\n",
    "    tmp_res = stts_mexico[state_name]\n",
    "    return tmp_res\n",
    "  except KeyError:\n",
    "    return 'SIN INFO.'\n",
    "\n",
    "def get_dep_with_break(key_name):\n",
    "  try:\n",
    "    tmp_res = None\n",
    "    key_name = key_name.upper()\n",
    "    dic_deps = {\n",
    "      'ESTABLECIMIENTO DE SALUD': 'ESTABL.\\nSALUD',\n",
    "      'ESTABLECIMIENTO DE EDUCACIÓN': 'ESTABL.\\nEDUCACIÓN',\n",
    "      'ESTABLECIMIENTO COMUNITARIO': 'ESTABL.\\nCOMUNITARIO',\n",
    "      'ESTABLECIMIENTO GOBIERNO': 'ESTABL.\\nGOBIERNO'\n",
    "    }\n",
    "    tmp_res = dic_deps[key_name]\n",
    "    return tmp_res\n",
    "  except KeyError:\n",
    "    return 'OTRA DEP.'\n",
    "\n",
    "def sin_ascentos(nombre: str)-> str:\n",
    "  \"\"\"\n",
    "  reemplazar tildes en palabras\n",
    "  \"\"\"\n",
    "  abc = [\n",
    "    ('Á', 'A'), ('É', 'E'), ('Í', 'I'), ('Ó', 'O'), ('Ú', 'U'), ('Ü', 'U'), \n",
    "    ('á', 'a'), ('é', 'e'), ('í', 'i'), ('ó', 'o'), ('ú', 'u'), ('ü', 'u')\n",
    "    ]\n",
    "  for a in abc:\n",
    "    nombre = nombre.replace(a[0], a[1])\n",
    "  return nombre\n",
    "\n",
    "def save_df_in_sheet_from_workbook(dataframe, sheetname, workbookname):\n",
    "  \"\"\"\n",
    "  Save a DataFrame into an Excel worksheet inside a specified Excel file.\n",
    "  \n",
    "  Arguments:\n",
    "  - dataframe: The DataFrame to be saved into the Excel worksheet\n",
    "  - sheetname: The name of the Excel worksheet in which the DataFrame will be written\n",
    "  - workbookname: The name of the Excel file in which the DataFrame will be saved\n",
    "  \"\"\"\n",
    "  try:\n",
    "    with pd.ExcelWriter(workbookname, mode='a') as writer:\n",
    "      dataframe.to_excel(writer, sheet_name=sheetname, index=None)\n",
    "  except FileNotFoundError:\n",
    "    with pd.ExcelWriter(workbookname) as writer:\n",
    "      dataframe.to_excel(writer, sheet_name=sheetname, index=None)\n",
    "  except ValueError:\n",
    "    pass\n",
    "\n",
    "# Función para validar latitudes\n",
    "def validar_latitud(latitud):\n",
    "  latitud = float(latitud)\n",
    "  latitud_patron = r'^[-+]?([1-8]?\\d(\\.\\d+)?|90(\\.0+)?)$'\n",
    "  return re.match(latitud_patron, str(latitud)) is not None\n",
    "\n",
    "# Patrón de regex para validar longitudes decimales\n",
    "\n",
    "# Función para validar longitudes\n",
    "def validar_longitud(longitud):\n",
    "  longitud = float(longitud)\n",
    "  # longitud_patron = r'^[-+]?(180(\\.0+)?|((1[0-7]\\d)|([1-9]?\\d))(\\.\\d+)?)$'\n",
    "  longitud_patron = r'^-?\\d+\\.\\d+$'\n",
    "  return re.match(longitud_patron, str(longitud)) is not None\n",
    "\n",
    "lst_reemplazos = [\n",
    "  ('delegación ', ''), ('delegacion ', ''), ('ciudad ', ''), ('alcaldia ', ''), ('alcaldía ', ''), ('ciudad de ', ''), ('cd. ', ''), ('sta. ', 'santa '), ('gral. ', 'general'), ('dr. ', 'doctor'), ('ciudad del ', ''), ('ciudad de ', ''), ('san ', ''),( '(', ''),( ')', ''), ('francisco', ''), ('juárez', ''), ('juarez', ''), ('ejido ', ''), ('jardines', '')\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar en memoria el archivo de excel\n",
    "data = pd.read_excel(io=file_to_analize, sheet_name=0, dtype={'Código postal*': object})\n",
    "\n",
    "# crear dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# eliminar data despues de convertirla en un dataframe\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2 style=\"color: #fb8500;\">El archivo tiene tiene 1,666 registros y 24 columnas</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lr_df -> última fila de dataframe\n",
    "lr = df.shape[0]\n",
    "display(HTML(f'<h2 style=\"color: #fb8500;\">El archivo tiene tiene {\"{:,}\".format(lr)} registros y {df.shape[1]} columnas</h2>'))\n",
    "\n",
    "del lr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t\t\tfont-weight: bolder;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columnas Clave Dependencia (1) y Dependencia (2) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importación del catálogo de ramos\n",
    "tRamos = pd.read_csv('./Compact_inegi_dbLocs/ramo.csv')\n",
    "lst_ramos = tRamos[\"cve_ramo\"].to_list()\n",
    "lst_desc_ramos = tRamos['descripcion'].to_list()\n",
    "dictRamosByID = dict(zip(lst_ramos, lst_desc_ramos))\n",
    "dictRamosByDesc = dict(zip(lst_desc_ramos, lst_ramos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actualizar la columna de clave dependencia y dependencia \n",
    "\n",
    "def update_row(row):\n",
    "    \n",
    "    clv = row['Clave de la Dependencia*']\n",
    "    dep = row['Dependencia*']\n",
    "    \n",
    "    # si el registro esta en la lista de claves pero el valor de diccionario no corresponde a la dependencia\n",
    "    if clv in lst_ramos and dictRamosByID[clv] != dep:\n",
    "        row['Dependencia*'] = dictRamosByID[clv]\n",
    "    \n",
    "    # si la clave no esta en la lista de ramos y la clave no es un valor vacio\n",
    "    elif clv not in lst_ramos and clv not in [' ', '']:\n",
    "        try:\n",
    "            row['Dependencia*'] = dictRamosByID[clv]\n",
    "            row['Clave de la Dependencia*'] = dictRamosByDesc[dep]\n",
    "        except KeyError:\n",
    "            row['Clave de la Dependencia*'] = ' '\n",
    "    return row\n",
    "\n",
    "df = df.apply(update_row, axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t\t\tfont-weight: bolder;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columna Clave de inmueble (3) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros SIN clave asignada: 26\n",
      "Registros clave DUPLICADA: 34\n",
      "Total registros: 60\n"
     ]
    }
   ],
   "source": [
    "# hacer el conteO de la clave inmueble, en primera instancia la clave de inmueble es una código único no vacio\n",
    "\n",
    "# agrupacion de las claves y conteo de las repeticiones por cada clave\n",
    "conteo_por_clvs = df.groupby(by='Clave del inmueble*').agg(regs_por_clave=('Clave del inmueble*', 'count')).reset_index()\n",
    "\n",
    "# mantener solo las claves cuya repetición es mayor a una\n",
    "conteo_por_clvs_duplicadas_clv =  conteo_por_clvs[conteo_por_clvs['regs_por_clave'] > 1].reset_index()\n",
    "\n",
    "# segmentacion de conteo donde las claves repetidas estan vacias, solo saber el número de registros vacios\n",
    "regs_sin_clv = conteo_por_clvs_duplicadas_clv[conteo_por_clvs_duplicadas_clv['Clave del inmueble*'] == \" \"]['regs_por_clave'][0]\n",
    "\n",
    "# de las claves que no estan vacias mostrar las claves cuyo conteo es mayor a 1 y su valor es diferente a vacio [\" \" o \"\"]\n",
    "regs_clv_dupl = conteo_por_clvs_duplicadas_clv[conteo_por_clvs_duplicadas_clv['Clave del inmueble*'] != \" \"]['regs_por_clave'].sum()\n",
    "\n",
    "print(f'Registros SIN clave asignada: {regs_sin_clv}\\nRegistros clave DUPLICADA: {regs_clv_dupl}\\nTotal registros: {regs_sin_clv + regs_clv_dupl}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupación de clave de inmueble y número de registros por clave\n",
    "conteo_por_clvs_duplicadas_clv = conteo_por_clvs_duplicadas_clv[['Clave del inmueble*','regs_por_clave']]\n",
    "\n",
    "# creación de una lista de todos los registros duplicados por clave y reemplazo de los vacios por un None\n",
    "lst_dupli_clv = [x if x != \" \" and x != \"\" else None for x in conteo_por_clvs_duplicadas_clv['Clave del inmueble*'].to_list()]\n",
    "\n",
    "lst_dupli_clv  = [elemento for elemento in lst_dupli_clv if elemento is not None]\n",
    "\n",
    "# segmentación del dataframe, filtrar solo los registros que estan repetidos en su clave de inmueble en la lista de claves duplicadas\n",
    "df_regs_duplicados_by_clv = df[df['Clave del inmueble*'].isin(lst_dupli_clv)].sort_values(by='Clave del inmueble*')\n",
    "\n",
    "# eliminar variables\n",
    "del tRamos, conteo_por_clvs_duplicadas_clv, lst_desc_ramos, conteo_por_clvs, df_regs_duplicados_by_clv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validación y creación de estatus de duplicidad en doc. interno\n",
    "df['status_intern_duplicidad'] = df['Clave del inmueble*'].apply(lambda x: 'clv interno duplicado' if x in lst_dupli_clv else 'clv interno no duplicado')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t\tfont-weight: bolder;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columna Tipo de inmuebles (5) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar catálogo de tipo de inmueble\n",
    "tTipoInmueble = pd.read_csv('./Compact_inegi_dbLocs/tipo_inmueble.csv')\n",
    "\n",
    "# crear lista de tipos de inmueble\n",
    "lstTipoInmueble = tTipoInmueble['tipo_inmueble'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modificar_tipo_inmueble(clv_dep, dep, tp_inmueble):\n",
    "  # si la clave de dependencias es igual a 11 y la dependencia es igual a EDUCACIÓN PÚBLICA \n",
    "  # entonces el tp_inmueble se reasigna a ESTABLECIMIENTO DE EDUCACIÓN\n",
    "  if clv_dep == 11 and dep == \"EDUCACIÓN PÚBLICA\":\n",
    "    tp_inmueble = \"ESTABLECIMIENTO DE EDUCACIÓN\"\n",
    "  \n",
    "  return tp_inmueble\n",
    "\n",
    "# Aplica la función a todas las filas del dataframe\n",
    "df[\"Tipo de inmuebles *\"] = df.apply(lambda x: modificar_tipo_inmueble(x[\"Clave de la Dependencia*\"], x[\"Dependencia*\"], x[\"Tipo de inmuebles *\"]), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminación de variables\n",
    "del tTipoInmueble\n",
    "del lstTipoInmueble\n",
    "del dictRamosByDesc\n",
    "del dictRamosByID\n",
    "del regs_clv_dupl\n",
    "del regs_sin_clv\n",
    "del lst_dupli_clv\n",
    "del lst_ramos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t\tfont-weight: bolder;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columna Subtipo de Inmueble (6) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import catálogo de subtipos de inmueble\n",
    "tSubtipoInmueble = pd.read_csv('./Compact_inegi_dbLocs/subtipo_inmueble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#               .d8888b.        d8888  .d8888b.   .d88888b.       888     888 888b    888 8888888 .d8888b.   .d88888b.  \n",
    "#              d88P  Y88b      d88888 d88P  Y88b d88P\" \"Y88b      888     888 8888b   888   888  d88P  Y88b d88P\" \"Y88b \n",
    "#              888    888     d88P888 Y88b.      888     888      888     888 88888b  888   888  888    888 888     888 \n",
    "#              888           d88P 888  \"Y888b.   888     888      888     888 888Y88b 888   888  888        888     888 \n",
    "#              888          d88P  888     \"Y88b. 888     888      888     888 888 Y88b888   888  888        888     888 \n",
    "#              888    888  d88P   888       \"888 888     888      888     888 888  Y88888   888  888    888 888     888 \n",
    "#              Y88b  d88P d8888888888 Y88b  d88P Y88b. .d88P      Y88b. .d88P 888   Y8888   888  Y88b  d88P Y88b. .d88P \n",
    "#               \"Y8888P\" d88P     888  \"Y8888P\"   \"Y88888P\"        \"Y88888P\"  888    Y888 8888888 \"Y8888P\"   \"Y88888P\"  \n",
    "\n",
    "def upgrade_subtipo_inmueble(nombre_inmueble, subtipo_inmueble):\n",
    "  # CASO ESPECIAL YA QUE EL NOMBRE DE LOS INMUEBLES COMO TAL ESTABAN SEGMENTADA \n",
    "  # UNA PARTE EN EL CAMPO NOMBRE DE INMUEBLE Y OTRA PARTE EN EL CAMPO SUBTIPO DE INMUEBLE\n",
    "  \n",
    "  # primera depuración para homologar nombres de inmuebles \n",
    "  \n",
    "  if subtipo_inmueble == 'COLEGIO DE EDUCACIÓN PROFESIONAL TÉCNICA (CONALEP)':\n",
    "    nombre_inmueble = f'{subtipo_inmueble} {nombre_inmueble}'\n",
    "\n",
    "  elif subtipo_inmueble == 'CENTRO DE BACHILLERATO TECNOLÓGICO AGROPECUARIO (CBTA)':\n",
    "    nombre_inmueble = f'CENTRO DE BACHILLERATO TECNOLÓGICO AGROPECUARIO - {nombre_inmueble}'\n",
    "\n",
    "  elif subtipo_inmueble == 'EXTENSIÓN (CBTA)':\n",
    "    nombre_inmueble = f'EXTENSIÓN {nombre_inmueble}'\n",
    "\n",
    "  elif subtipo_inmueble == 'OFICINA ADMINISTRATIVA':\n",
    "    nombre_inmueble = f'{nombre_inmueble} (Oficina administrativa)'\n",
    "\n",
    "  elif subtipo_inmueble == 'CENTRO DE ESTUDIOS TECNOLÓGICOS DEL MAR (CETMAR)':\n",
    "    nombre_inmueble = f'CENTRO DE ESTUDIOS TECNOLÓGICOS DEL MAR - {nombre_inmueble}'\n",
    "  \n",
    "  elif subtipo_inmueble == 'CENTRO DE ESTUDIOS DE BACHILLERATO (CEB)':\n",
    "    nombre_inmueble = f'CENTRO DE ESTUDIOS DE BACHILLERATO - {nombre_inmueble}'\n",
    "  \n",
    "  elif subtipo_inmueble == 'CENTRO DE ESTUDIOS TECNOLÓGICOS EN AGUAS CONTINENTALES (CETAC)':\n",
    "    nombre_inmueble = f'CENTRO DE ESTUDIOS TECNOLÓGICOS EN AGUAS CONTINENTALES - {nombre_inmueble}'\n",
    "  \n",
    "  elif subtipo_inmueble == 'EXTENSIÓN (CETMAR)':\n",
    "    nombre_inmueble = f'EXTENSIÓN {nombre_inmueble}'\n",
    "  \n",
    "  elif subtipo_inmueble == 'CENTRO DE BACHILLERATO TECNOLÓGICO FORESTAL (CBTF)':\n",
    "    nombre_inmueble = f'CENTRO DE BACHILLERATO TECNOLÓGICO FORESTAL - {nombre_inmueble}'\n",
    "  \n",
    "  elif subtipo_inmueble == 'COLEGIO DE EDUCACIÓN PROFESIONAL TÉCNICA DEL ESTADO DE TLAXCALA (CONALEP)':\n",
    "    nombre_inmueble = f'COLEGIO DE EDUCACIÓN PROFESIONAL TÉCNICA DEL ESTADO DE TLAXCALA - {nombre_inmueble}'\n",
    "  \n",
    "  elif subtipo_inmueble == 'EXTENSIÓN CBTA' or subtipo_inmueble == 'EXTENSIÓN (CBTF)':\n",
    "    nombre_inmueble = f'EXTENSIÓN - {nombre_inmueble}'\n",
    "  \n",
    "  elif subtipo_inmueble == 'UNIDADES DE CAPACITACIÓN PARA EL DESARROLLO RURAL (UNCADER)':\n",
    "    nombre_inmueble = f'UNIDADES DE CAPACITACIÓN PARA EL DESARROLLO RURAL - {nombre_inmueble}'\n",
    "  \n",
    "  elif 'CENTRO DE ESTUDIOS TECNOLÓGICOS INDUSTRIAL Y DE SERVICIOS' in subtipo_inmueble:\n",
    "    nombre_inmueble = f'CENTRO DE ESTUDIOS TECNOLÓGICOS INDUSTRIAL Y DE SERVICIOS -  {nombre_inmueble}'\n",
    "  \n",
    "  elif 'CENTRO DE BACHILLERATO TECNOLÓGICO INDUSTRIAL Y DE SERVICIOS' in subtipo_inmueble:\n",
    "    nombre_inmueble = f'CENTRO DE BACHILLERATO TECNOLÓGICO INDUSTRIAL Y DE SERVICIOS - {nombre_inmueble}'\n",
    "\n",
    "  elif subtipo_inmueble in ['CENTRO DE BACHILLERATO TECNOLÓGICO AGROPECUARIO No. 167', 'EXTENSIÓN (CETAC)', 'COLEGIO DE EDUCACIÓN PROFESIONAL TÉCNICA (CONALEP)', 'COLEGIO DE EDUCACIÓN PROFESIONAL TÉCNICA  DEL ESTADO DE TLAXCALA (CONALEP)', 'CENTRO MULTIMODAL DE ESTUDIOS CIENTIFICOS Y TECNOLOGICOS DEL MAR Y AGUAS CONTINENTALES', 'CENTRO DE INVESTIGACION DE RECURSOS NATURALES (CIRENA)', 'CENTRO DE BACHILLERATO TECNOLOGICO AGROPECUARIO NUM 191']:\n",
    "    nombre_inmueble = f'{subtipo_inmueble} - {nombre_inmueble}'\n",
    "  \n",
    "  return nombre_inmueble\n",
    "\n",
    "df['Nombre del inmueble*'] = df.apply(lambda x: upgrade_subtipo_inmueble(x['Nombre del inmueble*'], x['Subtipo de inmueble *']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_general_concepts_sub_tp_inmueble = []\n",
    "lst_dicts_inmueble_wrong_good = {}\n",
    "\n",
    "with open('./Compact_inegi_dbLocs/dict_subtp_inmueble.json', mode='r', encoding='utf-8') as f:\n",
    "  contenido = f.read()\n",
    "  f.close()\n",
    "  dict_subtp_inmueble = json.loads(contenido)\n",
    "  del contenido\n",
    "  \n",
    "\n",
    "for key in dict_subtp_inmueble.keys():\n",
    "  for value in dict_subtp_inmueble[key]:\n",
    "    lst_formas_str = [\n",
    "      f'{value}'.lower(), \n",
    "      f'{value}'.upper(), \n",
    "      f'{value}'.title(), \n",
    "      value, \n",
    "      sin_ascentos(f'{value}'), \n",
    "      sin_ascentos(f'{value}'.lower()), \n",
    "      sin_ascentos(f'{value}'.upper()), \n",
    "      sin_ascentos(f'{value}'.title())\n",
    "      ]\n",
    "    \n",
    "    for l in lst_formas_str:\n",
    "      lst_dicts_inmueble_wrong_good[l] = key\n",
    "      lst_general_concepts_sub_tp_inmueble.append(l)\n",
    "\n",
    "del lst_formas_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_right_subtp_inmueble(word):\n",
    "  \"\"\"\n",
    "  Description: \n",
    "      search the word in a list of wrong words with wrong meaning to the field and get the correct value from the catalog\n",
    "  \n",
    "  Args:\n",
    "      palabra (str): incorrect word to be search in the dictionary and get the right concept (subtipo inmueble)\n",
    "\n",
    "  Returns:\n",
    "      str: correct concept\n",
    "  \"\"\"\n",
    "  if word in lst_general_concepts_sub_tp_inmueble:\n",
    "    return lst_dicts_inmueble_wrong_good[word]\n",
    "  else:\n",
    "    return word\n",
    "  \n",
    "df['Subtipo de inmueble *'] = df['Subtipo de inmueble *'].apply(get_right_subtp_inmueble)\n",
    "\n",
    "# eliminar variable \n",
    "del lst_general_concepts_sub_tp_inmueble\n",
    "del lst_dicts_inmueble_wrong_good\n",
    "del dict_subtp_inmueble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subtipo de inmueble *</th>\n",
       "      <th>conteo_regs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PLANTEL EDUCACIÓN MEDIA SUPERIOR</td>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFICINA ADMINISTRATIVA</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Subtipo de inmueble *  conteo_regs\n",
       "1  PLANTEL EDUCACIÓN MEDIA SUPERIOR         1609\n",
       "0            OFICINA ADMINISTRATIVA           57"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conteo de registros por subtipos de inmuebles \n",
    "conteo_subtipo_inmueble = df.groupby(by='Subtipo de inmueble *').agg(conteo_regs=('Subtipo de inmueble *', 'count')).reset_index()\n",
    "ordenado_conteo_subtipo_inmueble = conteo_subtipo_inmueble.sort_values(by='conteo_regs', ascending=False)\n",
    "\n",
    "ordenado_conteo_subtipo_inmueble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desechar variables que ya no se van a usar\n",
    "del tSubtipoInmueble\n",
    "del conteo_subtipo_inmueble\n",
    "del ordenado_conteo_subtipo_inmueble\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columna Estado (8) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar catálogo de estado\n",
    "cat_edos = pd.read_csv('./Compact_inegi_dbLocs/cat_edos.csv', encoding='utf-8')\n",
    "cat_edos = cat_edos.rename(columns={'ï»¿id_edo': 'id_edo'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_correct_edo_name(edo_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Description:\n",
    "      get the id of the mexican state\n",
    "\n",
    "    Args:\n",
    "      edo_name (str): the name of the mexican state\n",
    "      cat_edos (pd.DataFrame): a DataFrame with columns 'id_edo' and 'edo' containing the\n",
    "                               mapping between state names and state ids\n",
    "\n",
    "    Returns:\n",
    "      int: the id of the mexican state, or None if the state name is not found\n",
    "    \"\"\"\n",
    "    edo_name = edo_name.upper().strip()\n",
    "    filtro = cat_edos[cat_edos['edo'] == edo_name]\n",
    "    if filtro.shape[0] == 1:\n",
    "        return filtro['id_edo'].iloc[0]\n",
    "    else:\n",
    "        temp_edo_name = None\n",
    "        \n",
    "        if edo_name in ['ESTADO DE MÉXICO', 'ESTADO DE MEXICO', 'MÉXICO']:\n",
    "            temp_edo_name = \"MÉXICO\"\n",
    "        \n",
    "        elif edo_name in ['COAHUILA']:\n",
    "            temp_edo_name = \"COAHUILA DE ZARAGOZA\" \n",
    "        \n",
    "        elif edo_name in ['MICHOACAN', 'MICHOACÁN']:\n",
    "            temp_edo_name = \"MICHOACÁN DE OCAMPO\"\n",
    "        \n",
    "        elif edo_name in ['VERACRUZ', 'VERACRUZ LLAVE']:\n",
    "            temp_edo_name = \"VERACRUZ DE IGNACIO DE LA LLAVE\"\n",
    "        \n",
    "        elif edo_name in ['SAN LUIS POTOSI']:\n",
    "            temp_edo_name = \"SAN LUIS POTOSÍ\"\n",
    "        \n",
    "        elif edo_name in ['QUERÉTARO DE ARTEAGA', 'QUERETARO DE ARTEAGA', 'QUERETARO', 'QUERÉTARO']:\n",
    "            temp_edo_name = \"QUERÉTARO\" \n",
    "        \n",
    "        # sección recursiva\n",
    "        if temp_edo_name is not None:\n",
    "            return get_id_correct_edo_name(temp_edo_name)\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# añadir la lista de id de cada uno de los estados\n",
    "lst_ids = df['Estado*'].apply(get_id_correct_edo_name)\n",
    "df.insert(7, 'id_edo', lst_ids)\n",
    "del lst_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edo_name_from_id_edo(id_edo: int) -> str:\n",
    "  \"\"\"\n",
    "  Description:\n",
    "    search the correct name in the mexican states directory\n",
    "  Aguments:\n",
    "    id_edo is a integer number from the mexican states directory \n",
    "  Return:\n",
    "    the correct name in the mexican states directory\n",
    "  \"\"\"\n",
    "  if id_edo != 0:\n",
    "    filtro = cat_edos[cat_edos.id_edo == id_edo]\n",
    "    if filtro.shape[0] == 1:\n",
    "      return filtro['edo'].iloc[0]\n",
    "    else:\n",
    "      return 'INFO. SIN DEFINIR'\n",
    "  else:\n",
    "    return 'INFO. SIN DEFINIR'\n",
    "\n",
    "# hacer correción en los nombres del campo estado\n",
    "df['Estado*'] = df['id_edo'].apply(get_edo_name_from_id_edo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminación de algunas variables\n",
    "del cat_edos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columna Municipio (9) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  importar base de datos municipios\n",
    "cat_mun = pd.read_csv('./Compact_inegi_dbLocs/AGEEML_20233271140141.csv', encoding='utf8', usecols=['CVE_ENT', 'NOM_ENT', 'CVE_MUN', 'NOM_MUN'])\n",
    "cat_mun = cat_mun.drop_duplicates()\n",
    "cat_mun['NOM_ENT'] = cat_mun['NOM_ENT'].str.lower()\n",
    "cat_mun['NOM_MUN'] = cat_mun['NOM_MUN'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar espacio\n",
    "df['Municipio*'] = df['Municipio*'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primera iteración tratando de encontrar los id de cada municipio en toda la base de datos de estado y municipio\n",
    "def get_id_mun(id_edo: int, edo_name: str) -> int:\n",
    "  \"\"\"\n",
    "  Description:\n",
    "\t\tget the id of the mun \n",
    "\tArguments:\n",
    "    id_edo = integer id from mexican state\n",
    "    edo_name = mexican state name\n",
    "\tReturn:\n",
    "    id mun\n",
    "  \"\"\"\n",
    "  edo_name = edo_name.lower().strip()\n",
    "  if id_edo != 0:\n",
    "    filter =  cat_mun[(cat_mun.CVE_ENT == id_edo) & (cat_mun.NOM_MUN == edo_name)]\n",
    "    if filter.shape[0] == 1:\n",
    "      return filter['CVE_MUN'].iloc[0]\n",
    "    else:\n",
    "      return 0\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "lst_id_mun = df.apply(lambda x: get_id_mun(x['id_edo'], x['Municipio*']), axis=1)\n",
    "df.insert(9, 'id_mun', lst_id_mun)\n",
    "del lst_id_mun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacer busqueda de municipios a partir de que en el filtrado aparezca una palabra similar a la que aparece en el documento que manda la dependencia\n",
    "def get_id_mun_contains(id_edo: int, id_mun: int, mun_name: str) -> int:\n",
    "  \"\"\"\n",
    "  Description:\n",
    "    get the id of the mun by the name of the mexican state using the methond contains id the cat_mun field\n",
    "  Arguments:\n",
    "    id_edo = int, id of the mexican state\n",
    "    id_mun = int, id of the mexican mun\n",
    "    mun_name = str, mun_name \n",
    "  Return:\n",
    "    id_mun with data type int\n",
    "  \"\"\"\n",
    "  mun_name = mun_name.lower()\n",
    "  if id_edo != 0 and id_mun == 0:\n",
    "    filtro = cat_mun[(cat_mun['CVE_ENT'] == id_edo) & (cat_mun['NOM_MUN'].str.contains(mun_name))]\n",
    "    if filtro.shape[0] == 1:\n",
    "      return filtro['CVE_MUN'].iloc[0]\n",
    "    else:\n",
    "      return 0\n",
    "  elif id_edo != 0 and id_mun != 0:\n",
    "    return id_mun\n",
    "\n",
    "df['id_mun'] = df.apply(lambda x: get_id_mun_contains(x['id_edo'], x['id_mun'], x['Municipio*']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buscar por registros sin ascentos y unidecode\n",
    "def unidecode_cat_mun(palabra):\n",
    "  return unidecode(palabra)\n",
    "\n",
    "# crear una columna con valores pasado por unidecode (borrar tildes y ñ)\n",
    "lst_cat_mun_unidecode = cat_mun['NOM_MUN'].apply(unidecode)\n",
    "cat_mun.insert(4, 'unidecode_mun', lst_cat_mun_unidecode)\n",
    "del lst_cat_mun_unidecode\n",
    "\n",
    "# crear columna con valores sin tildes\n",
    "lst_cat_mun_sin_tilde = cat_mun['NOM_MUN'].apply(sin_ascentos)\n",
    "cat_mun.insert(5, 'sin_ascentos_mun', lst_cat_mun_sin_tilde)\n",
    "del lst_cat_mun_sin_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buscar el municipio en la cat_mun previo se crean dos columnas una con unidecode y otra sin ascentos para hacer coincidencias \n",
    "def get_id_mun_unidecode_sinTildes(id_edo: int, id_mun: int, num_name: str) -> int:\n",
    "  \"\"\"\n",
    "  Descripcion: \n",
    "\t\tObtener el valor del municipio a partir de eliminar tildes en el nombre del municipio \n",
    "  Argumentos:\n",
    "\t\tid_edo = int, valor númerico de el id del estado\n",
    "\t\tid_mun = int, valor númerico del id del municipio\n",
    "\t\tmun_name = str, cadena de texto del nombre del municipio\n",
    "  Retorno:\n",
    "\t\tel id del municipio siempre y cuando de origen sea 0 y tambien el filtrado de información retorne al menos un valor\n",
    "  \"\"\"\n",
    "  \n",
    "  num_name = num_name.lower()\n",
    "  for x in lst_reemplazos:\n",
    "    num_name = num_name.replace(x[0], x[1])\n",
    "\n",
    "  num_name = num_name.strip()\n",
    "  \n",
    "  filtro = cat_mun[\n",
    "    (cat_mun['CVE_ENT'] == id_edo) & \n",
    "    (\n",
    "      (cat_mun['NOM_MUN'].str.contains(num_name)) | \n",
    "      (cat_mun['unidecode_mun'].str.contains(unidecode(num_name))) |\n",
    "      (cat_mun['sin_ascentos_mun'].str.contains(sin_ascentos(num_name)))\n",
    "      ) \n",
    "    ]\n",
    "  if filtro.shape[0] == 1 and id_edo > 0 and id_mun == 0:\n",
    "    return filtro['CVE_MUN'].iloc[0]\n",
    "  else:\n",
    "    return id_mun\n",
    "\n",
    "# aplicación de la función get_id_mun_unidecode_sinTildes\n",
    "df['id_mun'] = df.apply(lambda x: get_id_mun_unidecode_sinTildes(x['id_edo'], x['id_mun'], x['Municipio*']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear matriz cadenas  de texto e iterarlas para encontrar una coincidencia que devuelva solo un registro\n",
    "def get_id_mun_iter_str_mun(id_edo: int, id_mun: int, mun_name: str) -> int:\n",
    "  \"\"\"\n",
    "  Descripcion:\n",
    "    obtener el id de el municipio a partir del nombre, para ello se itera como lista el nombre del municipio y si el filtro da un resultado se retornara el id de ese sitio de lo contrario debera dejarlo en cero\n",
    "  Argumentos:\n",
    "    id_edo: int, es el id del estado\n",
    "    id_mun: int, es el id del municipio \n",
    "    mun_name: str, cadena de texto del nombre del municipio a ser convertida como cadena de texto\n",
    "  Return:\n",
    "    retorna el id del nombre del municpio \n",
    "  \"\"\"\n",
    "  if id_edo > 0 and id_mun == 0:\n",
    "    mun_name = mun_name.lower()\n",
    "    mun_name = mun_name.split(' ')\n",
    "    mun_name = list(sorted(mun_name, key=len, reverse=True))\n",
    "    len_mun_name = len(mun_name)\n",
    "\n",
    "    for x in enumerate(mun_name):\n",
    "      filtro = cat_mun[\n",
    "        (cat_mun['CVE_ENT'] == id_edo) & \n",
    "        (\n",
    "          (cat_mun['NOM_MUN'].str.contains(x[1])) | \n",
    "          (cat_mun['unidecode_mun'].str.contains(unidecode(x[1]))) | \n",
    "          (cat_mun['sin_ascentos_mun'].str.contains(sin_ascentos(x[1]))) \n",
    "        )\n",
    "        ]\n",
    "      \n",
    "      if x[0] +1 < len_mun_name:\n",
    "        if filtro.shape[0] == 1:\n",
    "          return filtro['CVE_MUN'].iloc[0]\n",
    "          break\n",
    "      \n",
    "      elif x[0]+1 == len_mun_name:\n",
    "        if filtro.shape[0] == 1:\n",
    "          return filtro['CVE_MUN'].iloc[0]\n",
    "          break\n",
    "        else:\n",
    "          return 0\n",
    "  else:\n",
    "    return id_mun\n",
    "\n",
    "# aplicar la función iterar valores de cadena de texto para obtener coincidencias\n",
    "df['id_mun'] = df.apply(lambda x: get_id_mun_iter_str_mun(x['id_edo'], x['id_mun'], x['Municipio*']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coincidencia exacta\n",
    "# crear matriz cadenas  de texto e iterarlas para encontrar una coincidencia que devuelva solo un registro\n",
    "def get_id_mun_iter_str_mun_coincidencia_exacta(id_edo: int, id_mun: int, mun_name: str) -> int:\n",
    "  \"\"\"\n",
    "  Descripcion:\n",
    "    obtener el id de el municipio a partir del nombre, para ello se itera como lista el nombre del municipio y si el filtro da un resultado se retornara el id de ese sitio de lo contrario debera dejarlo en cero\n",
    "  Argumentos:\n",
    "    id_edo: int, es el id del estado\n",
    "    id_mun: int, es el id del municipio \n",
    "    mun_name: str, cadena de texto del nombre del municipio a ser convertida como cadena de texto\n",
    "  Return:\n",
    "    retorna el id del nombre del municpio \n",
    "  \"\"\"\n",
    "  if id_edo > 0 and id_mun == 0:\n",
    "    mun_name = mun_name.lower()\n",
    "    mun_name = mun_name.split(' ')\n",
    "    mun_name = list(sorted(mun_name, key=len, reverse=True))\n",
    "    len_mun_name = len(mun_name)\n",
    "\n",
    "    for x in enumerate(mun_name):\n",
    "      filtro = cat_mun[\n",
    "        (cat_mun['CVE_ENT'] == id_edo) & \n",
    "        (\n",
    "          (cat_mun['NOM_MUN'] == x[1]) | \n",
    "          (cat_mun['unidecode_mun'] == unidecode(x[1])) | \n",
    "          (cat_mun['sin_ascentos_mun'] == sin_ascentos(x[1])) \n",
    "        )\n",
    "        \n",
    "        ]\n",
    "      \n",
    "      if x[0] +1 < len_mun_name:\n",
    "        if filtro.shape[0] == 1:\n",
    "          return filtro['CVE_MUN'].iloc[0]\n",
    "          break\n",
    "      \n",
    "      elif x[0]+1 == len_mun_name:\n",
    "        if filtro.shape[0] == 1:\n",
    "          return filtro['CVE_MUN'].iloc[0]\n",
    "          break\n",
    "        else:\n",
    "          return 0\n",
    "  else:\n",
    "    return id_mun\n",
    "\n",
    "# aplicar la función iterar valores de cadena de texto para obtener COINCIDENCIAS EXACTAS\n",
    "df['id_mun'] = df.apply(lambda x: get_id_mun_iter_str_mun_coincidencia_exacta(x['id_edo'], x['id_mun'], x['Municipio*']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacer la correción en el nombre de la localidad con base en el catálogo\n",
    "def get_mun_correct_name(id_edo: int, id_mun: int, mun_name: str) -> str:\n",
    "  if id_edo != 0 and id_mun != 0:\n",
    "    filtro = cat_mun[(cat_mun['CVE_ENT'] == id_edo) & (cat_mun['CVE_MUN'] == id_mun)]\n",
    "    if filtro.shape[0] == 1:\n",
    "      return f\"{filtro['NOM_MUN'].iloc[0]}\".title()\n",
    "    else:\n",
    "      return mun_name\n",
    "  else:\n",
    "    return mun_name\n",
    "\n",
    "df['Municipio*'] = df.apply(lambda x: get_mun_correct_name(x['id_edo'], x['id_mun'], x['Municipio*']), axis=1)\n",
    "\n",
    "# eliminar de memoria el catalogo de municipios\n",
    "del cat_mun"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columna Localidades (10) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar la columna 'id_mun' si es necesario\n",
    "df['id_mun'] = df['id_mun'].fillna(0) # Rellenar valores nulos con 0 o cualquier otro valor predeterminado\n",
    "df['id_mun'] = pd.to_numeric(df['id_mun'], errors='coerce') # Convertir a tipo numérico\n",
    "\n",
    "# Convertir la columna 'id_mun' a valores enteros y asignar el resultado a una nueva variable o a la misma columna\n",
    "df['id_mun'] = df['id_mun'].astype(int) # Convertir a valores enteros\n",
    "\n",
    "df['Localidad*'] = df['Localidad*'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quitar espacios inecesarios y reemplazar algunas palabras\n",
    "with warnings.catch_warnings():\n",
    "  warnings.filterwarnings('ignore')\n",
    "  for x in lst_reemplazos:\n",
    "    df['Localidad*'].str.replace(x[0], x[1])\n",
    "    \n",
    "df['Localidad*'] = df['Localidad*'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_val_locs(nom_localidad):\n",
    "  lst_reemplazos_2 = [\n",
    "    ('alcaldía ', ''), ('delegación ', '')\n",
    "  ]\n",
    "  for x in lst_reemplazos_2:\n",
    "    nom_localidad = nom_localidad.replace(x[0], x[1])\n",
    "    nom_localidad = nom_localidad.replace(sin_ascentos(x[0]), sin_ascentos(x[1]))\n",
    "  return nom_localidad\n",
    "\n",
    "df['Localidad*'] = df['Localidad*'].apply(replace_val_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar el catálogo de localidades\n",
    "cat_locs = pd.read_csv('./Compact_inegi_dbLocs/AGEEML_20233271140141.csv', usecols=['NOM_ENT','CVE_ENT', 'CVE_MUN', 'NOM_MUN', 'CVE_LOC', 'NOM_LOC'])\n",
    "cat_locs = cat_locs.drop_duplicates()\n",
    "cat_locs['NOM_LOC'] = cat_locs['NOM_LOC'].str.lower()\n",
    "cat_locs['unidecode_locs'] = cat_locs['NOM_LOC'].apply(unidecode)\n",
    "cat_locs['sinTilde_locs'] = cat_locs['NOM_LOC'].apply(sin_ascentos)\n",
    "\n",
    "# quitar espacios inecesarios\n",
    "cat_locs['unidecode_locs'] = cat_locs['unidecode_locs'].str.strip()\n",
    "cat_locs['sinTilde_locs'] = cat_locs['sinTilde_locs'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear primera iteración para encontrar la coincidencia exacta a partir del id edo, id mun y el nombre de la localidad, \n",
    "# SE GENERA LA COLUMNA DEL ID DE LA LOCALIDAD\n",
    "def get_id_loc(id_edo : int, id_mun : int, loc_name: str) -> int:\n",
    "  \"\"\"\n",
    "  Descripcion: \n",
    "    con esta funcion se obtiene el id de la localidad con ayuda de el id del estado, id del municipio y el nombre de la localidad\n",
    "  Argumentos:\n",
    "    id_loc: int, número entero que corresponde al id de la localidad\n",
    "    id_mun: int, número entero que corresponde al id del municipio\n",
    "    loc_name: str, cadena de texto que corresponde al nombre de la localidad\n",
    "  Retorno:\n",
    "    retorna el id de la localidad\n",
    "  \"\"\"\n",
    "  loc_name = loc_name.lower()\n",
    "  \n",
    "  loc_name = loc_name.strip()\n",
    "  \n",
    "  filtro = cat_locs[\n",
    "    (cat_locs['CVE_ENT'] == id_edo) & \n",
    "    (cat_locs['CVE_MUN'] == id_mun) & \n",
    "    (\n",
    "      (cat_locs['NOM_LOC'] == loc_name) |\n",
    "      (cat_locs['unidecode_locs'] == unidecode(loc_name)) | \n",
    "      (cat_locs['sinTilde_locs'] == sin_ascentos(loc_name))\n",
    "      )\n",
    "    ]\n",
    "  \n",
    "  if filtro.shape[0] == 1:\n",
    "    return filtro['CVE_LOC'].iloc[0]\n",
    "  elif loc_name == ' ' or loc_name == '':\n",
    "    return 0\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "# aplicación de la función get_id_loc\n",
    "lst_id_locs = df.apply(lambda x: get_id_loc(x['id_edo'], x['id_mun'], x['Localidad*']), axis=1)\n",
    "df.insert(11, 'id_loc', lst_id_locs)\n",
    "\n",
    "# eliminar la variable de la memoria\n",
    "del lst_id_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encontrar un match a partir del id del estado y del id de la localidad siempre y cuando se tenga el id del estado y el id de la localidad sea igual a cero\n",
    "def get_correction_mun_loc_ids(id_edo: int, id_mun: int, id_loc: int, loc_name: str) -> tuple:\n",
    "  \"\"\"\n",
    "  Descripcion: \n",
    "\t\tObtener el id de la localidad a partir del id del estado y el nombre de la localidad, si el filtrado da un resltado entonces se debe de hacer la correción\n",
    "  \"\"\"\n",
    "  if id_edo != 0 and id_loc == 0 and len(loc_name) != 0:\n",
    "    filtro = cat_locs[\n",
    "\t\t\t(cat_locs.CVE_ENT == id_edo) &\n",
    "\t\t\t(\n",
    "\t\t\t(cat_locs.NOM_LOC == loc_name) |\n",
    "\t\t\t(cat_locs.unidecode_locs == unidecode(loc_name)) |\n",
    "\t\t\t(cat_locs.sinTilde_locs == sin_ascentos(loc_name))\n",
    "\t\t\t)\n",
    "\t\t]\n",
    "    \n",
    "    if filtro.shape[0] == 1:\n",
    "      corr_id_mun = filtro['CVE_MUN'].iloc[0]\n",
    "      corr_id_loc = filtro['CVE_LOC'].iloc[0]\n",
    "      return corr_id_mun, corr_id_loc\n",
    "    else:\n",
    "      return (id_mun, id_loc)\n",
    "  else:\n",
    "    return (id_mun, id_loc)\n",
    "\n",
    "# aplicación de la función get_correction_mun_loc_ids\n",
    "lst_mun_locs_ids = df.apply(lambda x: get_correction_mun_loc_ids(x['id_edo'], x['id_mun'], x['id_loc'], x['Localidad*']), axis=1)\n",
    "\n",
    "# segmentación de la información por columna, deconstrucción\n",
    "df['id_mun'], df['id_loc'] = lst_mun_locs_ids.apply(lambda x: x[0]), lst_mun_locs_ids.apply(lambda x: x[1])\n",
    "\n",
    "# eliminación de la variable\n",
    "del lst_mun_locs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correction_mun_loc_ids_contains(id_edo: int, id_mun: int, id_loc: int, loc_name: str) -> tuple:\n",
    "  \"\"\"\n",
    "  Descripcion: \n",
    "\t\tobtener correción del id del municipio y localidad si el filtrado de id edo y nombre de la localidad retorna un valor que contenga el nombre de la localidad de la tabla dentro del catálogo\n",
    "  \"\"\"\n",
    "  if id_edo != 0 and id_loc == 0:\n",
    "    with warnings.catch_warnings():\n",
    "      warnings.filterwarnings('ignore')\n",
    "      filtro = cat_locs[\n",
    "        (cat_locs.CVE_ENT == id_edo) & \n",
    "        (\n",
    "          (cat_locs.NOM_LOC.str.contains(loc_name)) | \n",
    "          (cat_locs.unidecode_locs.str.contains(unidecode(loc_name))) |\n",
    "          (cat_locs.sinTilde_locs.str.contains(sin_ascentos(loc_name)))\n",
    "      )\n",
    "      ]\n",
    "      if filtro.shape[0] == 1:\n",
    "        corr_id_mun = filtro['CVE_MUN'].iloc[0]\n",
    "        corr_id_loc = filtro['CVE_LOC'].iloc[0]\n",
    "        return (corr_id_mun, corr_id_loc)\n",
    "      else:\n",
    "        return (id_mun, id_loc)\n",
    "  else:\n",
    "    return (id_mun, id_loc)\n",
    "    \n",
    "# aplicación de la función\n",
    "corr_id_mun_loc_contains = df.apply(lambda x: get_correction_mun_loc_ids_contains(x['id_edo'], x['id_mun'], x['id_loc'], x['Localidad*']), axis=1)\n",
    "\n",
    "# segmentar info por columnas:\n",
    "df['id_mun'], df['id_loc'] = corr_id_mun_loc_contains.apply(lambda x: x[0]), corr_id_mun_loc_contains.apply(lambda x: x[1])\n",
    "\n",
    "# eliminación de la variable \n",
    "del corr_id_mun_loc_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corr_id_mun_loc_substr(id_edo: int, id_mun: int, id_loc: int, loc_name: str) -> tuple:\n",
    "  \"\"\"\n",
    "  Descripcion:\n",
    "    obtener el id del estado en caso de que el nombre de la localidad tenga el caracter '(' en su nombre, en caso de que tenga ese caracter se aplica un substring se filtra por estado y el resultado de la extracción de la izquierda y en caso de que el filtrado regrese un registro se toma el id del municipio y la localidad del filtro\n",
    "  \"\"\"\n",
    "  if id_edo != 0 and id_loc == 0 and len(loc_name) > 0:\n",
    "\n",
    "    if '(' in loc_name:\n",
    "      parentesis = loc_name.find('(')\n",
    "      loc_name = loc_name[:parentesis].strip()\n",
    "      \n",
    "      filtro = cat_locs[\n",
    "      (cat_locs.CVE_ENT == id_edo) & \n",
    "      (\n",
    "        (cat_locs.NOM_LOC == loc_name) |\n",
    "        (cat_locs.unidecode_locs == unidecode(loc_name)) |\n",
    "        (cat_locs.sinTilde_locs == sin_ascentos(loc_name))\n",
    "      )\n",
    "      ]\n",
    "      \n",
    "      if filtro.shape[0] == 1:\n",
    "        corr_id_mun = filtro['CVE_MUN'].iloc[0]\n",
    "        corr_id_loc = filtro['CVE_LOC'].iloc[0]\n",
    "        return (corr_id_mun, corr_id_loc)\n",
    "      else:\n",
    "        return (id_mun, id_loc)\n",
    "    else:\n",
    "      return (id_mun, id_loc)\n",
    "  else:\n",
    "    return (id_mun, id_loc)\n",
    "\n",
    "# aplicación de la función\n",
    "lst_corr_id_mun_loc_substr = df.apply(lambda x: get_corr_id_mun_loc_substr(x['id_edo'], x['id_mun'], x['id_loc'], x['Localidad*']), axis=1)\n",
    "\n",
    "# reemplazo de los valores en columnas id_mun y id_loc\n",
    "df['id_mun'], df['id_loc'] = lst_corr_id_mun_loc_substr.apply(lambda x: x[0]), lst_corr_id_mun_loc_substr.apply(lambda x: x[1])\n",
    "\n",
    "# elinminacion de la variable\n",
    "del lst_corr_id_mun_loc_substr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esta función solo le debe de aplicar a los registros cuyo nombre de localidad aparece mas de una vez al momento de \n",
    "# hacer el filtrado por el id del estado, el id del municipio y el nombre de la localidad.\n",
    "# OBTENER LA LOCALIDAD CON REGISTRO DE ID MÁS CHICO DE LOS RESULTADOS FILTRADOS\n",
    "\n",
    "def get_smaller_id_loc_names_repited(id_edo: int, id_mun: int, id_loc: int, loc_name: str) -> int:\n",
    "  \"\"\"\n",
    "  Descripcion:\n",
    "\t\tobtener el id más pequeño del filtrado siempre y cuando haya mas de una coincidencia exacta al momento de filtrar la base de datos de los catálogos utilizando el id del estado, id del municipio y el nombre de la localidad\n",
    "  Argumentos:\n",
    "\t\tid_edo: int, es el número de índice en la bd de cat. localidades\n",
    "\t\tid_mun: int, es el número de indice del municipio en la bd de localidades\n",
    "\t\tid_loc: int, es el número de indice de la localidad en la bd de localidades\n",
    "\t\tloc_name: str, es el nombre de la localidad\n",
    "  Resultado:\n",
    "\t\tretorna el id de la localidad siempre y cuando haya mas de in registro cuyo nombre de la localidad es repetido en id edo, id municipio y nombre de la localidad\n",
    "  \"\"\"\n",
    "  if id_edo != 0 and id_mun != 0 and id_loc == 0 and loc_name not in [\" \", \"\"]:\n",
    "    \n",
    "    loc_name = loc_name.lower()\n",
    "    \n",
    "    for x in lst_reemplazos:\n",
    "      loc_name = loc_name.replace(x[0], x[1])\n",
    "    \n",
    "    loc_name = loc_name.strip()\n",
    "    \n",
    "    filtro = cat_locs[\n",
    "      (\n",
    "        (cat_locs['NOM_LOC'] == loc_name) |\n",
    "\t\t\t\t(cat_locs['unidecode_locs'] == unidecode(loc_name)) |\n",
    "\t\t\t\t(cat_locs['sinTilde_locs'] == sin_ascentos(loc_name)) ) & \n",
    "      (cat_locs['CVE_ENT'] == id_edo) &\n",
    "\t\t\t(cat_locs['CVE_MUN'] == id_mun)]\n",
    "    \n",
    "    if filtro.shape[0] > 1:\n",
    "      filtro.sort_values(by='CVE_LOC')\n",
    "      return filtro['CVE_LOC'].iloc[0]\n",
    "    else:\n",
    "      return id_loc\n",
    "  else:\n",
    "    return id_loc\n",
    "\n",
    "# aplicar la función de busqueda\n",
    "df['id_loc'] = df.apply(lambda x: get_smaller_id_loc_names_repited(x['id_edo'], x['id_mun'], x['id_loc'], x['Localidad*']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opción de include e iterar resultados:\n",
    "def get_smaller_id_loc_names_contains(id_edo: int, id_mun: int, id_loc: int, loc_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Descripcion:\n",
    "        obtener el id más pequeño del filtrado siempre y cuando haya mas de una coincidencia exacta al momento de filtrar la base de datos de los catálogos utilizando el id del estado, id del municipio y el nombre de la localidad\n",
    "    Argumentos:\n",
    "        id_edo: int, es el número de índice en la bd de cat. localidades\n",
    "        id_mun: int, es el número de indice del municipio en la bd de localidades\n",
    "        id_loc: int, es el número de indice de la localidad en la bd de localidades\n",
    "        loc_name: str, es el nombre de la localidad\n",
    "    Resultado:\n",
    "        retorna el id de la localidad siempre y cuando haya mas de in registro cuyo nombre de la localidad es repetido en id edo, id municipio y nombre de la localidad\n",
    "    \"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        \n",
    "        if id_edo != 0 and id_mun != 0 and id_loc == 0 and loc_name not in [\" \", \"\"]:\n",
    "            loc_name = loc_name.lower()\n",
    "            \n",
    "            for x in lst_reemplazos:\n",
    "                loc_name = loc_name.replace(x[0], x[1])\n",
    "            \n",
    "            loc_name = loc_name.strip()\n",
    "            \n",
    "            filtro = cat_locs[\n",
    "                (\n",
    "                    (cat_locs['NOM_LOC'].str.contains(loc_name)) |\n",
    "                    (cat_locs['unidecode_locs'].str.contains(loc_name)) |\n",
    "                    (cat_locs['sinTilde_locs'].str.contains(sin_ascentos(loc_name)))\n",
    "                    ) &\n",
    "                (cat_locs['CVE_ENT'] == id_edo) &\n",
    "                (cat_locs['CVE_MUN'] == id_mun)]\n",
    "            if filtro.shape[0] > 1:\n",
    "                filtro.sort_values(by='CVE_LOC')\n",
    "                return filtro['CVE_LOC'].iloc[0]\n",
    "            else:\n",
    "                return id_loc\n",
    "        else:\n",
    "            return id_loc\n",
    "\n",
    "# aplicar la función de busqueda\n",
    "df['id_loc'] = df.apply(lambda x: get_smaller_id_loc_names_contains(x['id_edo'], x['id_mun'], x['id_loc'], x['Localidad*']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16\tMICHOACÁN DE OCAMPO\t108\tZamora\t0\tARIO DE RAYÓN\n",
    "def get_id_loc_iter_vals_contains(id_edo: int, id_mun: int, id_loc: int, loc_name: str) -> int:\n",
    "  \"\"\"\n",
    "  Descripcion:\n",
    "    obtener el id del nombre de la localidad a partir de iterar el resultado de aplicar el filtro de aplicar por id estado, id municipio.\n",
    "  Argumentos:\n",
    "    id_edo: int, indice del estado\n",
    "    id_mun: int, indice del municipio a partir del estado\n",
    "    id_loc: int, indice de la localidad\n",
    "    nom:loc: str, nombre de la localidad\n",
    "  Retorno:\n",
    "  \"\"\"\n",
    "  if id_edo != 0 and id_mun != 0 and id_loc == 0 and id_edo != 9 and loc_name not in [\" \", \"\"]:\n",
    "    loc_name = loc_name.lower()\n",
    "    \n",
    "    for x in lst_reemplazos:\n",
    "      loc_name = loc_name.replace(x[0], x[1])\n",
    "      \n",
    "    loc_name = loc_name.strip()\n",
    "    \n",
    "    lst_loc_name = list(sorted(loc_name.split(\" \"), key=len, reverse=True))\n",
    "    len_lst_loc_name = len(lst_loc_name)\n",
    "\n",
    "    for x in enumerate(lst_loc_name):\n",
    "      iter = x[0]\n",
    "      palabra = x[1]\n",
    "      filtro = cat_locs[\n",
    "        (cat_locs.CVE_ENT == id_edo) & \n",
    "        (cat_locs.CVE_MUN == id_mun) & \n",
    "        (\n",
    "          (cat_locs.NOM_LOC.str.contains(palabra)) | \n",
    "          (cat_locs.unidecode_locs.str.contains(palabra)) | \n",
    "          (cat_locs.sinTilde_locs.str.contains(palabra))\n",
    "          )\n",
    "        ]\n",
    "\n",
    "      if iter + 1 < len_lst_loc_name:\n",
    "        if filtro.shape[0] == 1:\n",
    "          return filtro['CVE_LOC'].iloc[0]\n",
    "          break\n",
    "      else:\n",
    "        if filtro.shape[0] == 1:\n",
    "          return filtro['CVE_LOC'].iloc[0]\n",
    "          break\n",
    "        else:\n",
    "          return id_loc\n",
    "  else:\n",
    "    return id_loc\n",
    "\n",
    "# aplicación de la función\n",
    "df['id_loc'] = df.apply(lambda x: get_id_loc_iter_vals_contains(x['id_edo'], x['id_mun'], x['id_loc'], x['Localidad*']), axis=1)\n",
    "\n",
    "# eliminación de la lista de reemplazos\n",
    "del lst_reemplazos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Estado, Municipio y Localidad</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_mun_loc(id_edo: int, edo: str, id_mun: int, mun:str, id_loc: int, loc: str) -> tuple:\n",
    "  \"\"\"\n",
    "  Descripción:\n",
    "\t\tobtener el nombre del municipio y la localidad siempre y cuando ninguno de los id sea igual a cero\n",
    "\tArgumentos:\n",
    "\t\tid_edo: int, id del estado con base en el catálogo de localidades\n",
    "\t\tid_mun: int, id del municipio con base en el catálogo de localidades\n",
    "\t\tid_loc: int, id del localidad con base en el catálogo de localidades\n",
    "  \"\"\"\n",
    "  if id_edo != 0 and id_mun != 0 and id_loc != 0:\n",
    "    filtro = cat_locs[\n",
    "      (cat_locs.CVE_ENT == id_edo) &\n",
    "      (cat_locs.CVE_MUN == id_mun) & \n",
    "      (cat_locs.CVE_LOC == id_loc)]\n",
    "    if filtro.shape[0] == 1:\n",
    "      edo = f\"{filtro['NOM_ENT'].iloc[0]}\".title()\n",
    "      mun = f\"{filtro['NOM_MUN'].iloc[0]}\".title()\n",
    "      loc = f\"{filtro['NOM_LOC'].iloc[0]}\".title()\n",
    "      return (edo, mun, loc)\n",
    "    else:\n",
    "      return (f'{edo}'.title(), f'{mun}'.title(), f'{loc}'.title())\n",
    "  else:\n",
    "    return (f'{edo}'.title(), f'{mun}'.title(), f'{loc}'.title())\n",
    "  \n",
    "\n",
    "# generar lista de tuplas con correcciones en el nombre del estado, municipio y la localidad en los casos que aplica\n",
    "lst_reeplace_names_edo_mun_loc = df.apply( lambda x: get_name_mun_loc( x['id_edo'], x['Estado*'], x['id_mun'], x['Municipio*'], x['id_loc'], x['Localidad*']), axis=1  )\n",
    "\n",
    "# vaciado de la información a sus respectivas columnas\n",
    "df['Estado*'] = lst_reeplace_names_edo_mun_loc.apply(lambda x: x[0])\n",
    "df['Municipio*'] = lst_reeplace_names_edo_mun_loc.apply(lambda x: x[1])\n",
    "df['Localidad*'] = lst_reeplace_names_edo_mun_loc.apply(lambda x: x[2])\n",
    "\n",
    "# eliminación de variables\n",
    "del lst_reeplace_names_edo_mun_loc\n",
    "del cat_locs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columna Nombre de asentamiento humano y C.P. </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar el catálogo de códigos postales de sepomex\n",
    "cat_cp = pd.read_csv('./Compact_inegi_dbLocs/cp_sepomex.csv', dtype={'d_codigo': object}, usecols=['d_codigo', 'd_asenta', 'd_tipo_asenta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar espacios inescerarios de la columna de colonia\n",
    "df['Nombre de asentamiento humano (colonia)*'] = df['Nombre de asentamiento humano (colonia)*'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cp(col_name: str, col_cp: str) -> str:\n",
    "  \"\"\"\n",
    "  Descripción:\n",
    "    obtener nombre del asentamiento humano siempre y cuando el que viene definido cae es ciertos supuestos y el filtrado retorna al menos un resultado\n",
    "  \"\"\"\n",
    "  if col_name  in ['Nombre de asentamiento humano (colonia)', '', ' ', 'Nombre de asentamiento humano', 'asentamiento humano'] and len(f'{col_cp}') == 5:\n",
    "    \n",
    "    filtro = cat_cp[cat_cp.d_codigo == f'{col_cp}']\n",
    "    \n",
    "    if filtro.shape[0] != 0:\n",
    "      return filtro['d_asenta'].iloc[0]\n",
    "    else:\n",
    "      return col_name\n",
    "  else:\n",
    "    return col_name\n",
    "\n",
    "df['Nombre de asentamiento humano (colonia)*'] = df.apply(lambda x: get_cp(x['Nombre de asentamiento humano (colonia)*'], x['Código postal*']), axis=1)\n",
    "\n",
    "# eliminación de la variable cat_cp\n",
    "del cat_cp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Columna Latitud y Longitud</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[198], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mLatitud*\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mastype(\u001b[39mfloat\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:450\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 450\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    169\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "df['Latitud*'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[196], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[No Lat] \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(latitud)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[39m# aplicación de la validación de las latitudeds\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mLatitud*\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mLatitud*\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(status_latitud)\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1157\u001b[0m             values,\n\u001b[0;32m   1158\u001b[0m             f,\n\u001b[0;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1160\u001b[0m         )\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\davic\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[196], line 6\u001b[0m, in \u001b[0;36mstatus_latitud\u001b[1;34m(latitud)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstatus_latitud\u001b[39m(latitud):\n\u001b[0;32m      4\u001b[0m   \u001b[39m# global si_lat\u001b[39;00m\n\u001b[0;32m      5\u001b[0m   \u001b[39m# global no_lat\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m   \u001b[39mif\u001b[39;00m validar_latitud(latitud):\n\u001b[0;32m      7\u001b[0m     \u001b[39m# si_lat += 1\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m latitud\n\u001b[0;32m      9\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[39m# no_lat += 1\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[148], line 78\u001b[0m, in \u001b[0;36mvalidar_latitud\u001b[1;34m(latitud)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidar_latitud\u001b[39m(latitud):\n\u001b[1;32m---> 78\u001b[0m   latitud \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(latitud)\n\u001b[0;32m     79\u001b[0m   latitud_patron \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m^[-+]?([1-8]?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+)?|90(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m.0+)?)$\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     80\u001b[0m   \u001b[39mreturn\u001b[39;00m re\u001b[39m.\u001b[39mmatch(latitud_patron, \u001b[39mstr\u001b[39m(latitud)) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "# si_lat = 0\n",
    "# no_lat = 0\n",
    "def status_latitud(latitud):\n",
    "  # global si_lat\n",
    "  # global no_lat\n",
    "  if validar_latitud(latitud):\n",
    "    # si_lat += 1\n",
    "    return latitud\n",
    "  else:\n",
    "    # no_lat += 1\n",
    "    return f'[No Lat] {str(latitud)}'\n",
    "\n",
    "# aplicación de la validación de las latitudeds\n",
    "df['Latitud*'] = df['Latitud*'].apply(status_latitud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si_lon = 0\n",
    "# no_lon = 0\n",
    "def status_longitud(longitud):\n",
    "  # global si_lon\n",
    "  # global no_lon\n",
    "  if validar_latitud(longitud):\n",
    "    # si_lon += 1\n",
    "    return longitud\n",
    "  else:\n",
    "    # no_lon += 1\n",
    "    return f'[No Lon] {longitud}'\n",
    "\n",
    "# aplicación de la función para validar longitud\n",
    "df['Longitud*'] = df['Longitud*'].apply(status_longitud)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: red;\n",
    "\t\tcolor: white;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Localidades Prioritarias PROGRAMA DE COBERTURA SOCIAL</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_locs_pcs = pd.read_csv('./Compact_inegi_dbLocs/locs_prioritarias_programa_cobertura_social.csv', \n",
    "                           encoding='utf-8', \n",
    "                           usecols=['id_edo', 'id_mun', 'id_loc'], \n",
    "                           dtype={'id_edo': object, 'id_mun': object, 'id_loc': object})\n",
    "\n",
    "cat_locs_pcs['code_edo_mun_loc'] = cat_locs_pcs['id_edo'] + \" | \" + cat_locs_pcs['id_mun'] + \" | \" + cat_locs_pcs['id_loc']\n",
    "\n",
    "cat_locs_pcs = cat_locs_pcs.drop(columns=['id_edo', 'id_mun', 'id_loc'])\n",
    "\n",
    "list_locs_prio_pcs = cat_locs_pcs['code_edo_mun_loc'].to_list()\n",
    "\n",
    "del cat_locs_pcs\n",
    "\n",
    "def is_loc_priority(id_edo: int, id_mun: int, id_loc: int) -> str:\n",
    "  code = '{} | {} | {}'.format(id_edo, id_mun, id_loc)\n",
    "  if code in list_locs_prio_pcs:\n",
    "    return 'Prioritaria'\n",
    "  return 'No Prioritaria'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status_prioridad'] = df.apply(lambda x: is_loc_priority(x['id_edo'], x['id_mun'], x['id_loc']), axis=1)\n",
    "del list_locs_prio_pcs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: red;\n",
    "\t\tcolor: white;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Población femenina y masculina por localidad CENSO 2020</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "censo = pd.read_csv('./Compact_inegi_dbLocs/conjunto_de_datos_iter_00CSV20.csv', low_memory=False, usecols=['ENTIDAD', 'MUN', 'LOC', 'POBTOT', 'POBFEM', 'POBMAS'])\n",
    "\n",
    "censo = censo[\n",
    "\t(censo.ENTIDAD != 0) &\n",
    "\t(censo.MUN != 0) &\n",
    "\t(censo.LOC != 0)\n",
    "]\n",
    "\n",
    "# reemplazo de valores con * por un cero 0\n",
    "censo = censo.replace({'POBFEM': '*', 'POBMAS': '*'}, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population_by_loc(id_edo: int, id_mun: int, id_loc: int) -> tuple:\n",
    "  \"\"\"\n",
    "  Descripción:\n",
    "\t\tobtener el número de la población femenina y masculina a partir d<style>\n",
    "\th3{\n",
    "\t\tbackground-color: red;\n",
    "\t\tcolor: white;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Población femenina por localidad CENSO 2020</h3>el id del estado, id munucipio y el id de la localidad\n",
    "\t\tla tupla que retorna es = (población femenina, población masculina, porcentaje pop femenina, porcentaje pop masculina)\n",
    "  \"\"\"\n",
    "  if id_edo != 0 and id_mun != 0 and id_loc != 0:\n",
    "    filtro = censo[\n",
    "\t\t\t(censo.ENTIDAD == id_edo) &\n",
    "\t\t\t(censo.MUN == id_mun) &\n",
    "\t\t\t(censo.LOC == id_loc)\n",
    "\t\t]\n",
    "    if filtro.shape[0] == 1:\n",
    "      pob_fem = int(filtro['POBFEM'].iloc[0])\n",
    "      pob_mas = int(filtro['POBMAS'].iloc[0])\n",
    "      try: \n",
    "        pop_tot = pob_fem + pob_mas\n",
    "        por_fem = round((pob_fem / pop_tot) * 100, 2)\n",
    "        por_mas = round((pob_mas / pop_tot) * 100, 2)\n",
    "        return (pob_fem, pob_mas, por_fem, por_mas )\n",
    "      except (ValueError, ZeroDivisionError):\n",
    "        return (pob_fem, pob_mas, 0, 0)\n",
    "    else:\n",
    "      return (0, 0, 0, 0)\n",
    "  else:\n",
    "    return (0, 0, 0, 0)\n",
    "\n",
    "# aplicación de la función \n",
    "lst_tuplas_pop_por_loc = df.apply(lambda x: get_population_by_loc(x['id_edo'], x['id_mun'], x['id_loc']), axis=1)\n",
    "\n",
    "# creación de las nuevas columnas\n",
    "df['pob_femenina'] =  lst_tuplas_pop_por_loc.apply(lambda x: x[0])\n",
    "df['pob_masculina'] =  lst_tuplas_pop_por_loc.apply(lambda x: x[1])\n",
    "df['porcentaje_pop_fem']  =  lst_tuplas_pop_por_loc.apply(lambda x: x[2])\n",
    "df['porcentaje_pop_mas']  =  lst_tuplas_pop_por_loc.apply(lambda x: x[3])\n",
    "\n",
    "# eliminar la variable\n",
    "del lst_tuplas_pop_por_loc\n",
    "del censo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: red;\n",
    "\t\tcolor: white;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Base de datos CFE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar la base de datos de CFE\n",
    "data_cfe = pd.read_excel('./Compact_inegi_dbLocs/avance_ordenes_cfe_teit.xlsx', usecols=['entidad_id', 'municipio_id', 'localidad_clave', 'inmueble_clave', 'inmueble_nombre', 'conexion_estatus'], dtype={'inmueble_clave': object, 'inmueble_nombre': object, 'conexion_estatus': object})\n",
    "\n",
    "# eliminar los espacios inecesarios de la base de datos de cfe en su columna clave de inmueble\n",
    "data_cfe['inmueble_clave'] = data_cfe['inmueble_clave'].str.strip()\n",
    "\n",
    "# convertir el nombre del sitio a minuscula\n",
    "data_cfe['inmueble_nombre'] = data_cfe['inmueble_nombre'].str.lower()\n",
    "\n",
    "# solo obtener los registros los cuales tienen un estatus de \"instalada\"\n",
    "df_instaladas = data_cfe[data_cfe['conexion_estatus'] == 'Instalada']\n",
    "\n",
    "# eliminar la base de datos de cfe para ahoorar espacio en memoria y solo usar el df de instalados\n",
    "del data_cfe\n",
    "\n",
    "# crear una lista de claves de sitios instalados, primero quitamos duplicados y eliminamos vacios \n",
    "lst_instaladas = df_instaladas['inmueble_clave'].drop_duplicates().dropna()\n",
    "\n",
    "# reasignamos el valor de lst_instaladas para solo mantener los registros cuyo largo de información sea mayor a 5:\n",
    "lst_instaladas = [f\"{x}\".upper() for x in lst_instaladas if len(x) > 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cfe_connected(clv_inmueble: str) -> str:\n",
    "  if clv_inmueble in lst_instaladas:\n",
    "    return 'Conectada'\n",
    "  return 'No conectada'\n",
    "\n",
    "# aplicación de la función para conocer el status de la conexión\n",
    "df['cfe_conexion_status'] = df['Clave del inmueble*'].apply(is_cfe_connected)\n",
    "\n",
    "# eliminar variable de lista de instaladas claves\n",
    "del lst_instaladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst_temp_clvs = []\n",
    "# def generate_key_installed(id_edo, id_mun, id_loc, name_site):\n",
    "#   global lst_temp_clvs\n",
    "#   temp = \"{} | {} | {} | {}\".format(id_edo, id_mun, id_loc, name_site)\n",
    "#   lst_keys = [f'{temp}'.lower(), f'{temp}'.upper(), f'{temp}'.title(), sin_ascentos(f'{temp}'), unidecode(f'{temp}')]\n",
    "#   for x in lst_keys:\n",
    "#     lst_temp_clvs.append(x)\n",
    "\n",
    "# df_instaladas.apply(lambda x: generate_key_installed(x['entidad_id'], x['municipio_id'], x['localidad_clave'], x['inmueble_nombre']), axis=1)\n",
    "\n",
    "# LO DE ARRIBA NO FUNCIONA ECHARLE UN OJO Y COMPRENDERLO\n",
    "\n",
    "def generate_key_installed(id_edo, id_mun, id_loc, name_site):\n",
    "  temp = \"{} | {} | {} | {}\".format(id_edo, id_mun, id_loc, name_site)\n",
    "  # lst_keys = [f'{temp}'.lower(), f'{temp}'.upper(), f'{temp}'.title()]\n",
    "  lst_keys = [f'{temp}'.lower(), f'{temp}'.upper(), f'{temp}'.title(), sin_ascentos(f'{temp}'.lower()), unidecode(f'{temp}'.lower())]\n",
    "  # Assuming sin_ascentos is a function defined elsewhere\n",
    "  lst_keys += [sin_ascentos(f'{temp}'), unidecode(f'{temp}')]\n",
    "  return lst_keys\n",
    "\n",
    "lst_temp_clvs = []\n",
    "for _, row in df_instaladas.iterrows():\n",
    "  lst_temp_clvs += generate_key_installed(row['entidad_id'], row['municipio_id'], row['localidad_clave'], row['inmueble_nombre'])\n",
    "  \n",
    "del df_instaladas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_key_in_lst_clvs(id_edo, id_mun, id_loc, site_name, status_conection):\n",
    "  if status_conection == 'No conectada':\n",
    "    site_name = site_name.lower()\n",
    "    temp_sin_ascentos  = \"{} | {} | {} | {}\".format(id_edo, id_mun, id_loc, sin_ascentos(site_name))\n",
    "    temp_unidecode  = \"{} | {} | {} | {}\".format(id_edo, id_mun, id_loc, unidecode(site_name))\n",
    "    temp_lower = \"{} | {} | {} | {}\".format(id_edo, id_mun, id_loc, site_name.lower())\n",
    "    if (temp_sin_ascentos in lst_temp_clvs) or (temp_unidecode in lst_temp_clvs) or (temp_lower in lst_temp_clvs):\n",
    "      return 'Conectada'\n",
    "    return status_conection\n",
    "  return status_conection\n",
    "\n",
    "# aplicación de la función\n",
    "df['cfe_conexion_status'] = df.apply(lambda x: validate_key_in_lst_clvs(x['id_edo'], x['id_mun'], x['id_loc'], x['Nombre del inmueble*'], x['cfe_conexion_status']), axis=1)\n",
    "\n",
    "# eliminar la lista de claves\n",
    "del lst_temp_clvs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: red;\n",
    "\t\tcolor: white;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Base de Datos Preliminar PCSP</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_pcsp = pd.read_csv('./Compact_inegi_dbLocs/respaldo_copia_rusp.csv', low_memory=False, encoding='utf-8', usecols=['Clave del inmueble*', 'Nombre del inmueble*', 'Id_Edo', 'ID_Mun', 'ID_Loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar espacios en columnas de nombre del inmueble y clave del inmueble\n",
    "db_pcsp['Clave del inmueble*'] = db_pcsp['Clave del inmueble*'].str.strip()\n",
    "db_pcsp['Nombre del inmueble*'] = db_pcsp['Nombre del inmueble*'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_clvs_pcsp = db_pcsp[db_pcsp['Clave del inmueble*'].str.len() > 4]['Clave del inmueble*'].drop_duplicates().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar_clv_in_preliminar_pcsp(clave):\n",
    "  if clave in lst_clvs_pcsp:\n",
    "    return 'SI'\n",
    "  return 'NO'\n",
    "\n",
    "# aplicación de la función validación en la base de datos preliminar pcsp\n",
    "df['en_preliminar_pcsp'] = df['Clave del inmueble*'].apply(validar_clv_in_preliminar_pcsp)\n",
    "\n",
    "# eliminación de la variable lista lst_clvs_pcsp\n",
    "del lst_clvs_pcsp\n",
    "del db_pcsp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "\th3{\n",
    "\t\tbackground-color: orange;\n",
    "\t\tcolor: black;\n",
    "\t\ttext-align: center;\n",
    "\t\tborder: 2px solid red;\n",
    "\t}\n",
    "</style>\n",
    "<h3>Exportaciones sobre archivo original</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \t\t\t\t\t╔═╗═╗ ╦╔═╗╔═╗╦═╗╔╦╗╔═╗╦═╗  ╔═╗╦═╗╔═╗╦ ╦╦╦  ╦╔═╗  ╔═╗╦═╗╦╔═╗╦╔╗╔╔═╗╦    ╔═╗╔═╗╔╗╔  ╔═╗╦═╗╦ ╦╔═╗╔═╗╔═╗\n",
    "# \t\t\t\t\t║╣ ╔╩╦╝╠═╝║ ║╠╦╝ ║ ╠═╣╠╦╝  ╠═╣╠╦╝║  ╠═╣║╚╗╔╝║ ║  ║ ║╠╦╝║║ ╦║║║║╠═╣║    ║  ║ ║║║║  ║  ╠╦╝║ ║║  ║╣ ╚═╗\n",
    "# \t\t\t\t\t╚═╝╩ ╚═╩  ╚═╝╩╚═ ╩ ╩ ╩╩╚═  ╩ ╩╩╚═╚═╝╩ ╩╩ ╚╝ ╚═╝  ╚═╝╩╚═╩╚═╝╩╝╚╝╩ ╩╩═╝  ╚═╝╚═╝╝╚╝  ╚═╝╩╚═╚═╝╚═╝╚═╝╚═╝\n",
    "save_df_changes(df, 'archivo_original_cruces_aplicados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           ╔═╗═╗ ╦╔═╗╔═╗╦═╗╔╦╗╔═╗╦═╗  ╔═╗╦═╗╔═╗╦ ╦╦╦  ╦╔═╗  ╔═╗╦╔╗╔  ╔╦╗╦ ╦╔═╗╦  ╦╔═╗╔═╗╔╦╗╔═╗╔═╗\n",
    "#           ║╣ ╔╩╦╝╠═╝║ ║╠╦╝ ║ ╠═╣╠╦╝  ╠═╣╠╦╝║  ╠═╣║╚╗╔╝║ ║  ╚═╗║║║║   ║║║ ║╠═╝║  ║║  ╠═╣ ║║║ ║╚═╗\n",
    "#           ╚═╝╩ ╚═╩  ╚═╝╩╚═ ╩ ╩ ╩╩╚═  ╩ ╩╩╚═╚═╝╩ ╩╩ ╚╝ ╚═╝  ╚═╝╩╝╚╝  ═╩╝╚═╝╩  ╩═╝╩╚═╝╩ ╩═╩╝╚═╝╚═╝\n",
    "\n",
    "#           ╔╗╔╔═╗  ╔═╗╔═╗╔╗╔╔═╗╔═╗╔╦╗╔═╗╔╦╗╔═╗  ╔═╗╔═╗╔═╗  ╔╦╗╔═╗╦╔╦╗\n",
    "#           ║║║║ ║  ║  ║ ║║║║║╣ ║   ║ ╠═╣ ║║║ ║  ║  ╠╣ ║╣    ║ ║╣ ║ ║ \n",
    "#           ╝╚╝╚═╝  ╚═╝╚═╝╝╚╝╚═╝╚═╝ ╩ ╩ ╩═╩╝╚═╝  ╚═╝╚  ╚═╝   ╩ ╚═╝╩ ╩ \n",
    "\n",
    "#           ╔╗╔╔═╗  ╔═╗╔╗╔  ╔═╗╦═╗╔═╗╦  ╦╔╦╗╦╔╗╔╔═╗╦═╗  ╔═╗╔═╗╔═╗╔═╗\n",
    "#           ║║║║ ║  ║╣ ║║║  ╠═╝╠╦╝║╣ ║  ║║║║║║║║╠═╣╠╦╝  ╠═╝║  ╚═╗╠═╝\n",
    "#           ╝╚╝╚═╝  ╚═╝╝╚╝  ╩  ╩╚═╚═╝╩═╝╩╩ ╩╩╝╚╝╩ ╩╩╚═  ╩  ╚═╝╚═╝╩  \n",
    "\n",
    "# segmentación de registros no conectados con base en el doc de cfe teit y que no esten en la base de datos preliminar de pcsp\n",
    "archivo_segmentado  = df[(df['cfe_conexion_status'] == 'No conectada') & (df['en_preliminar_pcsp'] == 'NO')]\n",
    "\n",
    "# primer intento para eliminar registros duplicados que sean exactamente igual en cada uno de los campos\n",
    "archivo_segmentado = archivo_segmentado.drop_duplicates()\n",
    "\n",
    "# filtrar solo registros duplicados\n",
    "duplicados_inter = archivo_segmentado[(archivo_segmentado['status_intern_duplicidad'] == 'clv interno duplicado')]\n",
    "\n",
    "# iterar la lista de filas dependiendo del número de las mismas\n",
    "lr_duplicados_inter = duplicados_inter.shape[0]\n",
    "\n",
    "# lista donde se van almacenar los números de caracteres por registro para poder eliminar los más bajos en números de registros a partir de la clave repetida\n",
    "lens_duplicados_inter = []\n",
    "\n",
    "# iterar todas las filas y todas las columnas del documento de filtro repetidos internos para obtener el conteo de caracteres por cada repetido\n",
    "# iterar filas\n",
    "for r in range(0, lr_duplicados_inter):\n",
    "  # número de caractéres\n",
    "  w = 0\n",
    "  # iterar columnas\n",
    "  for c in range(0, 29):\n",
    "    # incremento de conteo de caracteres\n",
    "    w += len(f'{duplicados_inter.iloc[r,c]}')\n",
    "  # agregar conteo a lista \n",
    "  lens_duplicados_inter.append(w)\n",
    "\n",
    "# añadir el conteo de caracteres al subfiltro\n",
    "duplicados_inter.insert(2, 'len_row_record', lens_duplicados_inter)\n",
    "\n",
    "# segmentar subfiltro por el conteo de caracteres y la claves duplicadas en subfiltro\n",
    "duplicados_inter = duplicados_inter[['len_row_record', 'Clave del inmueble*']]\n",
    "\n",
    "# crear ordenado por clave (de forma alfabética) y el conteo de caracteres (descendente)\n",
    "# duplicados_inter.sort_values(by=['len_row_record', 'Clave del inmueble*'], ascending=[False, False])\n",
    "\n",
    "# crear lista de indices del dataframe contenedor\n",
    "list_indices = []\n",
    "\n",
    "# bucle para obtener el índice de cada registro que esta duplicado en sus claves\n",
    "for r in range(0, lr_duplicados_inter):\n",
    "  \n",
    "  len_record = duplicados_inter['len_row_record'].iloc[r]\n",
    "  clv = duplicados_inter['Clave del inmueble*'].iloc[r]\n",
    "  \n",
    "  # filtrado para obtener \n",
    "  indice = duplicados_inter[\n",
    "    ( duplicados_inter['len_row_record'] == len_record) &\n",
    "    ( duplicados_inter['Clave del inmueble*'] == clv )\n",
    "    ].index.tolist()\n",
    "  \n",
    "  list_indices.append(indice[0])\n",
    "\n",
    "# insertar la lista de indices en el subfiltrado\n",
    "duplicados_inter.insert(0, 'indice_container', list_indices)\n",
    "\n",
    "# crear lista de solo duplicados \n",
    "lst_duplicados = list(set(duplicados_inter['Clave del inmueble*'].to_list()))\n",
    "\n",
    "# lst_index_to_del\n",
    "lst_index_to_del = []\n",
    "\n",
    "# bucle para iterar el subfiltro y solo contemplar para su eliminación cada registro que este por debajo del registro que tenga más contenido\n",
    "for ele in lst_duplicados:\n",
    "  subfiltro = duplicados_inter[duplicados_inter['Clave del inmueble*'] == ele].sort_values(by='len_row_record', ascending=False)\n",
    "  for r in subfiltro['indice_container'].iloc[1:]:\n",
    "    lst_index_to_del.append(r)\n",
    "\n",
    "# reasignar la segmentación donde solo se queden los archivos que no estan repetidos, que no estan en la base de datos preliminar pcsp y que no aparezcan en la lista de conectados de CFE TEIT\n",
    "archivo_segmentado = archivo_segmentado.drop(index= lst_index_to_del)\n",
    "\n",
    "# guardar el archivo segmentado con registros unicos\n",
    "save_df_changes(archivo_segmentado, 'archivo_unicos_NO_pcsp_NO_cfe')\n",
    "\n",
    "# eliminar variables de la memoria\n",
    "del duplicados_inter, lr_duplicados_inter, lens_duplicados_inter, list_indices, lst_duplicados, lst_index_to_del, subfiltro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar columas que no se ocupan para las gráficas PARA AHORRAR ESPACIO EN MEMORIA\n",
    "col_eliminables = ['Clave de la Dependencia*', 'Descripción de la ubicación', 'Tipo de vialidad*', 'Nombre de vialidad*', 'Número exterior*', 'Número interior*', 'Nombre de asentamiento humano (colonia)*', 'Código postal*', 'Luz eléctrica*', 'Material del Techo del inmueble', 'Nombre completo del responsable del sitio*', 'Correo institucional*', 'número teléfónico', 'Prioridad establecida', 'status_intern_duplicidad', 'status_prioridad', 'pob_femenina', 'pob_masculina', 'porcentaje_pop_fem', 'porcentaje_pop_mas', 'cfe_conexion_status', 'en_preliminar_pcsp']\n",
    "\n",
    "df.drop(columns=col_eliminables)\n",
    "\n",
    "archivo_segmentado.drop(columns=col_eliminables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                ╔═╗╔═╗╔╗╔╔╦╗╔═╗╔═╗  ╦═╗╔═╗╔═╗╦╔═╗╔╦╗╦═╗╔═╗╔═╗  ╔═╗╔═╗╦═╗  ╔═╗╔═╗╔╦╗╔═╗╔╦╗╔═╗\n",
    "#                ║  ║ ║║║║ ║ ║╣ ║ ║  ╠╦╝║╣ ║ ╦║╚═╗ ║ ╠╦╝║ ║╚═╗  ╠═╝║ ║╠╦╝  ║╣ ╚═╗ ║ ╠═╣ ║║║ ║\n",
    "#                ╚═╝╚═╝╝╚╝ ╩ ╚═╝╚═╝  ╩╚═╚═╝╚═╝╩╚═╝ ╩ ╩╚═╚═╝╚═╝  ╩  ╚═╝╩╚═  ╚═╝╚═╝ ╩ ╩ ╩═╩╝╚═╝\n",
    "# Calvin S\n",
    "# https://patorjk.com/software/taag/#p=display&f=Calvin%20S&t=CONTEO%20REGISTROS%20POR%20ESTADO\n",
    "\n",
    "display(HTML('<h2 style=\"background-color: #ff7d00; color: white;\" >Los sitios que en el campo de \"Estado*\" no hayan tenido información en automático se clasifican con el concepto de \"SIN INFORMACIÓN\", los registros eliminados caen en las siguientes condiciones: <br><ol><li>Son registros que según el archivo de CFE TEIT ya tienen estatus de conectado</li><li>El sitio ya estaba previamente contemplado en preliminar del PCSP</li><li>El registro estaba duplicado dentro del mismo archivo que manda la dependencia o estado</li></ol></h3>'))\n",
    "\n",
    "# conteo de sitios por estado de la república ARCHIVO ORIGINAL\n",
    "conteo_regs_por_edo_original = df.groupby(by='Estado*').agg(conteo_x_edo_original=('Estado*', 'count')).reset_index().sort_values(by='conteo_x_edo_original', ascending = False)\n",
    "\n",
    "# conteo de sitios por estado de la república ARCHIVO SEGMENTADO\n",
    "conteo_regs_por_edo_segmentado = archivo_segmentado.groupby(by='Estado*').agg(conteo_x_edo_segmentado=('Estado*', 'count')).reset_index().sort_values(by='conteo_x_edo_segmentado', ascending=False)\n",
    "\n",
    "# unión de los dataframe conteo por estado\n",
    "merge_conteo_x_edo = pd.merge(left=conteo_regs_por_edo_original, right=conteo_regs_por_edo_segmentado, on='Estado*')\n",
    "\n",
    "# añadir acrónimo de estado para ahorrar espacio en el gráfico\n",
    "merge_conteo_x_edo.insert(0, 'acronimo', merge_conteo_x_edo['Estado*'].apply(get_acronym))\n",
    "\n",
    "# eliminar la columna de estado para ahorrar espacio\n",
    "merge_conteo_x_edo = merge_conteo_x_edo.drop(columns=['Estado*'])\n",
    "\n",
    "# ordenar de forma descendente a partir de la columna del conteo por estado de referencia dek archivo original\n",
    "merge_conteo_x_edo = merge_conteo_x_edo.sort_values(by='conteo_x_edo_original', ascending=False)\n",
    "\n",
    "count_x_edo_original, count_x_edo_segmentado = '{:,}'.format(merge_conteo_x_edo['conteo_x_edo_original'].sum()), '{:,}'.format(merge_conteo_x_edo['conteo_x_edo_segmentado'].sum())\n",
    "\n",
    "# guardar archivo con el dataframe de conteo de registros por estado\n",
    "save_df_in_sheet_from_workbook(merge_conteo_x_edo, 'cont_regs_x_edo', wb_final_results)\n",
    "\n",
    "# hacer una nueva columna con el estatus de la variación\n",
    "merge_conteo_x_edo['hay_cambios'] = merge_conteo_x_edo['conteo_x_edo_original'] != merge_conteo_x_edo['conteo_x_edo_segmentado']\n",
    "\n",
    "# solo seleccionar los registros que tienen alguna variación en sus registros al momento de ser depurados\n",
    "merge_conteo_x_edo = merge_conteo_x_edo[merge_conteo_x_edo['hay_cambios'] == True]\n",
    "\n",
    "# eliminar la columna bool cambios\n",
    "merge_conteo_x_edo = merge_conteo_x_edo.drop(columns=['hay_cambios'])\n",
    "\n",
    "# --------------- CREACIÓN DE GRÁFICA -------------------------------\n",
    "\n",
    "# crear instancia de gráfica\n",
    "chrt_merge_conteo_x_edo = merge_conteo_x_edo.plot(\n",
    "  kind='bar', figsize=(20, 5), title= f'conteo sitios por estado', width = 0.8, xlabel= 'Estado de la república mexicana', ylabel= 'Sitios por estado', color = ['#691C32', '#BC955C']\n",
    "  )\n",
    "\n",
    "# cambiar el tamaño de la fuente del las etiquetas de las barras del eje x\n",
    "chrt_merge_conteo_x_edo.set_xticklabels(labels=merge_conteo_x_edo['acronimo'], fontsize=9)\n",
    "\n",
    "for x in chrt_merge_conteo_x_edo.containers:\n",
    "  chrt_merge_conteo_x_edo.bar_label(x, fontsize=9)\n",
    "\n",
    "grupo_nombres = [f'Sitios en archivo original({count_x_edo_original})', f'Sitios en archivo segmentado ({count_x_edo_segmentado})']\n",
    "chrt_merge_conteo_x_edo.legend(grupo_nombres, loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# elimar variables:\n",
    "del conteo_regs_por_edo_original, conteo_regs_por_edo_segmentado, merge_conteo_x_edo, chrt_merge_conteo_x_edo, grupo_nombres\n",
    "\n",
    "# # --------------- CREACIÓN DE GRÁFICA -------------------------------\n",
    "\n",
    "# # Crear una figura y un eje\n",
    "# fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 12))\n",
    "\n",
    "# # Establecer el título del gráfico\n",
    "# [ax[lbl[0]].set_title(lbl[1], fontsize=10) for lbl in enumerate([f'Conteo de sitios por estado ORIGINAL ({count_x_edo_original} sitios)', f'Conteo de sitios por estado SEGMENTADO ({count_x_edo_segmentado} sitios)'])]\n",
    "\n",
    "# # graficar subplots (2)\n",
    "# [merge_conteo_x_edo.plot(kind='bar', ax=ax[lbl[0]], y=lbl[1]) for lbl in enumerate(['conteo_x_edo_original', 'conteo_x_edo_segmentado'])]\n",
    "\n",
    "# # Agregar etiquetas al subplot\n",
    "# [ax[x].set_xticklabels(merge_conteo_x_edo['acronimo'], fontsize=10) for x in range(0,2)]\n",
    "\n",
    "# # # Eliminar las etiquetas del eje x en ambos subplots\n",
    "# # # ax[0].set_xticklabels([])\n",
    "# # ax[1].set_xticklabels([])\n",
    "\n",
    "# # Añadir los valores a las columnas subplot 0\n",
    "# for i in range(0,2):\n",
    "#     for x in ax[i].containers:\n",
    "#         ax[i].bar_label(x)\n",
    "\n",
    "# # mostrar la figura\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           ╔═╗╔═╗╔╗╔╔╦╗╔═╗╔═╗  ╔═╗╦╔╦╗╦╔═╗╔═╗  ╔═╗╔═╗╦═╗  ╔╦╗╔═╗╔═╗╔═╗╔╗╔╔╦╗╔═╗╔╗╔╔═╗╦╔═╗\n",
    "#           ║  ║ ║║║║ ║ ║╣ ║ ║  ╚═╗║ ║ ║║ ║╚═╗  ╠═╝║ ║╠╦╝   ║║║╣ ╠═╝║╣ ║║║ ║║║╣ ║║║║  ║╠═╣\n",
    "#           ╚═╝╚═╝╝╚╝ ╩ ╚═╝╚═╝  ╚═╝╩ ╩ ╩╚═╝╚═╝  ╩  ╚═╝╩╚═  ═╩╝╚═╝╩  ╚═╝╝╚╝═╩╝╚═╝╝╚╝╚═╝╩╩ ╩\n",
    "\n",
    "# agrupación de registros por estado y tipo de dependencia [ARCHIVO ORIGINAL Y SEGMENTADO]\n",
    "conteo_dep_archivo_original = df['Tipo de inmuebles *'].value_counts().rename_axis('dependencia').reset_index(name='conteo_original')\n",
    "conteo_dep_archivo_segmentado = archivo_segmentado['Tipo de inmuebles *'].value_counts().rename_axis('dependencia').reset_index(name='conteo_segmentado')\n",
    "\n",
    "# merge conteo de archivo original y segmentado\n",
    "merge_conteo_regs_x_dep = pd.merge(left=conteo_dep_archivo_original, right=conteo_dep_archivo_segmentado, on='dependencia')\n",
    "\n",
    "# guardar la segmentación de los datos\n",
    "save_df_in_sheet_from_workbook(merge_conteo_regs_x_dep, 'sitios_x_dep', wb_final_results)\n",
    "\n",
    "# añadir el nombre corto por dependencia para ahorrar espacio en gráfica\n",
    "merge_conteo_regs_x_dep.insert(0,'shrt_name_dep',  merge_conteo_regs_x_dep['dependencia'].apply(get_dep_with_break)) \n",
    "\n",
    "# eliminar la columna de dependencia para ahorrar espacio en df\n",
    "merge_conteo_regs_x_dep = merge_conteo_regs_x_dep.drop(columns=['dependencia'])\n",
    "\n",
    "# sumatoria\n",
    "ttl_regs_dep_original, ttl_regs_dep_segmentado = merge_conteo_regs_x_dep['conteo_original'].sum(), merge_conteo_regs_x_dep['conteo_segmentado'].sum() \n",
    "\n",
    "# ***************************** GRÁFICA *********************************************************************\n",
    "\n",
    "chrt_merge_conteo_regs_x_dep = merge_conteo_regs_x_dep.plot(\n",
    "  kind='bar',   figsize=(20, 5),  title= f'conteo sitios por tipo dependencia',  width = 0.8,\n",
    "  xlabel= 'Dependencia',  ylabel= 'Sitios por dependencia',  color = ['#691C32', '#BC955C'])\n",
    "\n",
    "# cambiar el tamaño de la fuente del las etiquetas de las barras del eje x\n",
    "chrt_merge_conteo_regs_x_dep.set_xticklabels(labels=merge_conteo_regs_x_dep['shrt_name_dep'], fontsize=9)\n",
    "\n",
    "# añadir valores a las columnas \n",
    "for x in chrt_merge_conteo_regs_x_dep.containers:\n",
    "  chrt_merge_conteo_regs_x_dep.bar_label(x, fontsize=9)\n",
    "\n",
    "grupo_nombres = [f'Sitios en archivo ORIGINAL ({ttl_regs_dep_original})', f'Sitios en archivo SEGMENTADO ({ttl_regs_dep_segmentado})']\n",
    "chrt_merge_conteo_regs_x_dep.legend(grupo_nombres, loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del chrt_merge_conteo_regs_x_dep, conteo_dep_archivo_original, conteo_dep_archivo_segmentado, ttl_regs_dep_original, ttl_regs_dep_segmentado, grupo_nombres, merge_conteo_regs_x_dep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\t\t\t\t ╔═╗╦╔╗╔  ╔═╗╦  ╔═╗╦  ╦╔═╗╔═╗  ╔═╗  ╔╦╗╦ ╦╔═╗╦  ╦╔═╗╔═╗╔╦╗╔═╗╔═╗  ╔═╗╔╗╔  ╔╦╗╦╔═╗╔╦╗╔═╗  ╔═╗╦═╗╔═╗╦ ╦╦╦  ╦╔═╗\n",
    "#\t\t\t\t ╚═╗║║║║  ║  ║  ╠═╣╚╗╔╝║╣ ╚═╗  ║ ║   ║║║ ║╠═╝║  ║║  ╠═╣ ║║╠═╣╚═╗  ║╣ ║║║  ║║║║╚═╗║║║║ ║  ╠═╣╠╦╝║  ╠═╣║╚╗╔╝║ ║\n",
    "#\t\t\t\t ╚═╝╩╝╚╝  ╚═╝╩═╝╩ ╩ ╚╝ ╚═╝╚═╝  ╚═╝  ═╩╝╚═╝╩  ╩═╝╩╚═╝╩ ╩═╩╝╩ ╩╚═╝  ╚═╝╝╚╝  ╩ ╩╩╚═╝╩ ╩╚═╝  ╩ ╩╩╚═╚═╝╩ ╩╩ ╚╝ ╚═╝\n",
    "\n",
    "# df['Clave del inmueble*'].value_counts().rename_axis('Clave').reset_index(name='Conteo')\n",
    "# df['Clave del inmueble*'].value_counts().reset_index().rename(columns={'index': 'Clave', 'Clave del inmueble*': 'Conteo'})\n",
    "# df['Clave del inmueble*'].value_counts().rename('Conteo').reset_index(name='Clave')\n",
    "# df['Clave del inmueble*'].value_counts().to_frame('Conteo').reset_index().rename(columns={'index': 'Clave'})\n",
    "# conteo_claves = df['Clave del inmueble*'].value_counts().rename('Conteo').reset_index()\n",
    "\n",
    "display(HTML('<h2 style=\"background-color: #ff7d00; color: white;\" >Las claves que se duplican puede variar, una clave puede repetirse al menos 2 veces.</h3>'))\n",
    "\n",
    "# conteo de claves\n",
    "conteo_claves = df['Clave del inmueble*'].value_counts().rename_axis('Clave').reset_index(name='Conteo')\n",
    "\n",
    "# eliminación de espacios\n",
    "conteo_claves['Clave'] = conteo_claves['Clave'].str.strip()\n",
    "\n",
    "sin_clv = conteo_claves[conteo_claves['Clave'] == '']['Conteo'].sum()\n",
    "clv_unicas = conteo_claves[(conteo_claves['Conteo'] == 1) & (conteo_claves['Clave'] != '')]['Conteo'].sum()\n",
    "clv_duplicadas = conteo_claves[(conteo_claves['Conteo'] > 1) & (conteo_claves['Clave'] != '')]\n",
    "\n",
    "\n",
    "# guardar los registros que tienen las claves repetidas \n",
    "save_df_in_sheet_from_workbook(dataframe= clv_duplicadas, sheetname='clvs_duplicadas', workbookname=wb_final_results)\n",
    "\n",
    "# claves duplicadas se reasigna valor \n",
    "clv_duplicadas = clv_duplicadas['Conteo'].sum()\n",
    "\n",
    "# data para crear un nuevo dataframe\n",
    "data_conte_status_clvs = {\n",
    "  'status': ['sin_clave', 'duplicadas', 'unicas'],\n",
    "  'conteo': [sin_clv, clv_duplicadas, clv_unicas] }\n",
    "\n",
    "total_regs = '{:,}'.format(sum([sin_clv, clv_duplicadas, clv_unicas]))\n",
    "\n",
    "# dataframe conteo por status de claves\n",
    "df_conteo_clv = pd.DataFrame(data_conte_status_clvs)\n",
    "\n",
    "# convertir el valor \"conteo\" a numérico\n",
    "df_conteo_clv['conteo'] = df_conteo_clv['conteo'].astype(int)\n",
    "\n",
    "# ordenado del df status claves por conteo de forma descendente\n",
    "df_conteo_clv = df_conteo_clv.sort_values(by='conteo', ascending=False)\n",
    "\n",
    "# ****************************************************************************************\n",
    "\n",
    "# Crear una figura y un eje\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "\n",
    "# Establecer el título del gráfico\n",
    "ax[0].set_title(f'Conteo por status de claves ({total_regs})', fontsize=10)\n",
    "ax[1].set_title(f'Porcentaje por status de claves ({total_regs})', fontsize=10)\n",
    "\n",
    "# graficar el primer subplot como un gráfico de barras\n",
    "df_conteo_clv.plot(kind='bar', ax=ax[0])\n",
    "\n",
    "# Agregar etiquetas al eje x del primer subplot\n",
    "ax[0].set_xticklabels(df_conteo_clv['status'], fontsize=10)\n",
    "\n",
    "# graficar el segundo subplot como un gráfico de pastel\n",
    "df_conteo_clv.plot(kind='pie', y='conteo', labels=df_conteo_clv['status'], ax=ax[1], autopct='%1.1f%%', textprops={'fontsize': 10})\n",
    "\n",
    "# Eliminar las etiquetas del eje x en ambos subplots\n",
    "# ax[0].set_xticklabels([])\n",
    "ax[1].set_xticklabels([])\n",
    "\n",
    "# Añadir los valores a las columnas subplot 0\n",
    "for x in ax[0].containers:\n",
    "  ax[0].bar_label(x)\n",
    "\n",
    "# mostrar la figura\n",
    "plt.show()\n",
    "\n",
    "# eliminar variables\n",
    "del conteo_claves, sin_clv, clv_unicas, clv_duplicadas, data_conte_status_clvs, total_regs, df_conteo_clv, fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\t\t ╦  ╔═╗╔═╗╔═╗╦  ╦╔╦╗╔═╗╔╦╗╔═╗╔═╗  ╔═╗╦╔╗╔  ╦╔╦╗    ╦╔╗╔╔═╗╔═╗╦\n",
    "#\t\t ║  ║ ║║  ╠═╣║  ║ ║║╠═╣ ║║║╣ ╚═╗  ╚═╗║║║║  ║ ║║    ║║║║║╣ ║ ╦║\n",
    "#\t\t ╩═╝╚═╝╚═╝╩ ╩╩═╝╩═╩╝╩ ╩═╩╝╚═╝╚═╝  ╚═╝╩╝╚╝  ╩═╩╝────╩╝╚╝╚═╝╚═╝╩\n",
    "\n",
    "display(HTML('<h2 style=\"background-color: #ff7d00; color: white; text-align: center;\">La razón por la que no se puede asignar el identificador clave (ID) es por que el nombre de la localidad que registran en el archivo no corresponde con los que vienen en la base de datos del INEh</h2>'))\n",
    "\n",
    "# creación del conteo por filtro\n",
    "locs_sin_id_x_edo_original = df[(df['id_loc'] == 0)]['Estado*'].value_counts().rename_axis('Estado').reset_index(name='conteo_original')\n",
    "locs_sin_id_x_edo_segmentado = archivo_segmentado[(archivo_segmentado['id_loc'] == 0)]['Estado*'].value_counts().rename_axis('Estado').reset_index(name='conteo_segmentado')\n",
    "\n",
    "\n",
    "# unión de los dataframes agrupados por tipo de archivo\n",
    "merge_locs_sin_id_x_edo = pd.merge(left=locs_sin_id_x_edo_original, right=locs_sin_id_x_edo_segmentado, on='Estado')\n",
    "\n",
    "# insertar columna de acrónimo para ahorrrar espacio en gráfico\n",
    "merge_locs_sin_id_x_edo.insert(0, 'acronimo', merge_locs_sin_id_x_edo['Estado'].apply(get_acronym) )\n",
    "\n",
    "# eliminar la columna de estado para ahorrar espacio en df\n",
    "merge_locs_sin_id_x_edo = merge_locs_sin_id_x_edo.drop(columns=['Estado'])\n",
    "\n",
    "# guardar el archivo unido\n",
    "save_df_in_sheet_from_workbook(merge_locs_sin_id_x_edo, 'locs_sin_id_loc', wb_final_results)\n",
    "\n",
    "# totales por archivo, localidades sin id\n",
    "ttl_merge_locs_sin_id_x_edo_original = '{:,}'.format(merge_locs_sin_id_x_edo['conteo_original'].sum())\n",
    "ttl_merge_locs_sin_id_x_edo_segmentado = '{:,}'.format(merge_locs_sin_id_x_edo['conteo_segmentado'].sum())\n",
    "# ------------------------ CREACIÓN DE GRÁFICO -----------------------------------------------\n",
    "\n",
    "chrt_merge_locs_sin_id_x_edo = merge_locs_sin_id_x_edo.plot(\n",
    "  kind='bar',   figsize=(20, 5),  title= 'Sitios no localizados por estado',  width = 0.8,\n",
    "  xlabel= 'Edo. de la República',  ylabel= 'Sitios por estado',  color = ['#691C32', '#BC955C'])\n",
    "\n",
    "# cambiar el tamaño de la fuente del las etiquetas de las barras del eje x\n",
    "chrt_merge_locs_sin_id_x_edo.set_xticklabels(labels=merge_locs_sin_id_x_edo['acronimo'], fontsize=10)\n",
    "\n",
    "# añadir valores a las columnas \n",
    "for x in chrt_merge_locs_sin_id_x_edo.containers:\n",
    "  chrt_merge_locs_sin_id_x_edo.bar_label(x, fontsize=9)\n",
    "\n",
    "# personalizar los leyendas \n",
    "grupo_nombres = [f'Sitios en locs. sin ID en archivo ORIGINAL ({ttl_merge_locs_sin_id_x_edo_original})', f'Sitios en locs. sin ID en archivo SEGMENTADO ({ttl_merge_locs_sin_id_x_edo_segmentado})']\n",
    "chrt_merge_locs_sin_id_x_edo.legend(grupo_nombres, loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# eliminación de variables\n",
    "del locs_sin_id_x_edo_original, locs_sin_id_x_edo_segmentado, merge_locs_sin_id_x_edo, ttl_merge_locs_sin_id_x_edo_original, ttl_merge_locs_sin_id_x_edo_segmentado, chrt_merge_locs_sin_id_x_edo, grupo_nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<h2 style=\"background-color: #ff7d00; color: white; text-align: center;\">Considerar que hay sitios en localidades que no se les pudo asignar id de la localidad por lo tanto no se pudieron casificar si son prioritarias o no prioritarias</h2>'))\n",
    "\n",
    "# crear dataframe conteo de sitios no prioritarios\n",
    "sitios_locs_no_prio_original = df[df['status_prioridad'] == 'Prioritaria']['Estado*'].value_counts().rename_axis('estado').reset_index(name='conteo_prioritarias_original')\n",
    "sitios_locs_no_prio_segmentado = archivo_segmentado[(archivo_segmentado['status_prioridad'] == 'Prioritaria')]['Estado*'].value_counts().rename_axis('estado').reset_index(name='conteo_prioritarias_segmentado')\n",
    "\n",
    "# unión de los df de archivo original y de segmentación\n",
    "merge_sitios_locs_prio = pd.merge(left=sitios_locs_no_prio_original, right=sitios_locs_no_prio_segmentado, on='estado')\n",
    "\n",
    "# agregar la columna de acronimo para ahorrar espacio en gráfica\n",
    "merge_sitios_locs_prio.insert(0, 'acronimo', merge_sitios_locs_prio['estado'].apply(get_acronym))\n",
    "\n",
    "# eliminar la columna de estado\n",
    "merge_sitios_locs_prio = merge_sitios_locs_prio.drop(columns=['estado'])\n",
    "\n",
    "# guardar segmentación \n",
    "save_df_in_sheet_from_workbook(merge_sitios_locs_prio, 'sitios_locs_prio', wb_final_results)\n",
    "\n",
    "ttl_sitios_locs_prio_original = '{:,}'.format(merge_sitios_locs_prio['conteo_prioritarias_original'].sum())\n",
    "ttl_sitios_locs_prio_merge = '{:,}'.format(merge_sitios_locs_prio['conteo_prioritarias_segmentado'].sum())\n",
    "\n",
    "# **************************************** CREACIÓN DE GRÁFICO **************************************************************\n",
    "# crear instancia de gráfico\n",
    "chrt_merge_sitios_locs_prio = merge_sitios_locs_prio.plot(\n",
    "\tkind='bar', title='Sitios en localidades prioritarias por estado', figsize=(20, 5), width= 0.8, xlabel='Estado de la Rep. Mexicana', ylabel='Sitios por estado', color = ['#691C32', '#BC955C']\n",
    ")\n",
    "\n",
    "# cambiar el tamaño de la fuente del las etiquetas de las barras del eje x\n",
    "chrt_merge_sitios_locs_prio.set_xticklabels(labels=merge_sitios_locs_prio['acronimo'], fontsize=10)\n",
    "\n",
    "# añadir valores a las columnas \n",
    "for x in chrt_merge_sitios_locs_prio.containers:\n",
    "  chrt_merge_sitios_locs_prio.bar_label(x, fontsize=9)\n",
    "\n",
    "# personalizar los leyendas \n",
    "grupo_nombres = [f'Sitios en locs. prioritarias ORIGINAL ({ttl_sitios_locs_prio_original})', f'Sitios en locs. prioritarias SEGMENTADO ({ttl_sitios_locs_prio_merge})']\n",
    "chrt_merge_sitios_locs_prio.legend(grupo_nombres, loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del sitios_locs_no_prio_original, sitios_locs_no_prio_segmentado, merge_sitios_locs_prio, ttl_sitios_locs_prio_original, ttl_sitios_locs_prio_merge, chrt_merge_sitios_locs_prio, grupo_nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \t\t╔═╗╦╔╦╗╦╔═╗╔═╗  ╦  ╔═╗╔═╗╔═╗   ╔═╗╦═╗╦╔═╗   ╦ ╦  ╔╦╗╦ ╦ ╦╔═╗╦═╗╔═╗╔═╗    ╔═╗╔═╗╔╗╔  ╔═╗╦    ╔╦╗╔═╗╔╗╔╔═╗╔═╗  ╦  ╔═╗  ╔╦╗╦╔╦╗╔═╗╔╦╗\n",
    "# \t\t╚═╗║ ║ ║║ ║╚═╗  ║  ║ ║║  ╚═╗   ╠═╝╠╦╝║║ ║   ╚╦╝  ║║║║ ║ ║║╣ ╠╦╝║╣ ╚═╗    ╚═╗║ ║║║║  ╠═╣║    ║║║║╣ ║║║║ ║╚═╗  ║  ╠═╣  ║║║║ ║ ╠═╣ ║║\n",
    "# \t\t╚═╝╩ ╩ ╩╚═╝╚═╝  ╩═╝╚═╝╚═╝╚═╝o  ╩  ╩╚═╩╚═╝o   ╩   ╩ ╩╚═╝╚╝╚═╝╩╚═╚═╝╚═╝    ╚═╝╚═╝╝╚╝  ╩ ╩╩═╝  ╩ ╩╚═╝╝╚╝╚═╝╚═╝  ╩═╝╩ ╩  ╩ ╩╩ ╩ ╩ ╩═╩╝\n",
    "\n",
    "# segmentación de información donde las localidades sean prioritarias y la pobla\n",
    "sitios_loc_prio_y_pop_fem_ge50_origin = df[\n",
    "    (df['porcentaje_pop_fem'] >= 50) & (df['status_prioridad'] == 'Prioritaria')\n",
    "    ]['Estado*'].value_counts().rename_axis('Estado').reset_index(name='conteo_original')\n",
    "\n",
    "\n",
    "sitios_loc_prio_y_pop_fem_ge50_segment = archivo_segmentado[\n",
    "    (archivo_segmentado['porcentaje_pop_fem'] >= 50) & (archivo_segmentado['status_prioridad'] == 'Prioritaria')\n",
    "    ]['Estado*'].value_counts().rename_axis('Estado').reset_index(name='conteo_segmentado')\n",
    "\n",
    "# unir los dataframes de conteos de sitios prioritarios con pob. fem >= 50 en df original y segmentado\n",
    "merge_sitios_loc_prio_y_pop_fem_ge50 = pd.merge(left=sitios_loc_prio_y_pop_fem_ge50_origin, right=sitios_loc_prio_y_pop_fem_ge50_segment, on='Estado')\n",
    "\n",
    "# agregar la columna de acronimo \n",
    "merge_sitios_loc_prio_y_pop_fem_ge50.insert(0, 'acronimo', merge_sitios_loc_prio_y_pop_fem_ge50['Estado'].apply(get_acronym))\n",
    "\n",
    "# eliminar la columna de estado\n",
    "merge_sitios_loc_prio_y_pop_fem_ge50 = merge_sitios_loc_prio_y_pop_fem_ge50.drop(columns=['Estado'])\n",
    "\n",
    "# guardar la segmentación\n",
    "save_df_in_sheet_from_workbook(merge_sitios_loc_prio_y_pop_fem_ge50, 'sitios_locs_prio_pob_fem_ge50', wb_final_results)\n",
    "\n",
    "ttl_merge_sitios_loc_prio_y_pop_fem_ge50_original = '{:,}'.format(merge_sitios_loc_prio_y_pop_fem_ge50['conteo_original'].sum())\n",
    "ttl_merge_sitios_loc_prio_y_pop_fem_ge50_segmentado = '{:,}'.format(merge_sitios_loc_prio_y_pop_fem_ge50['conteo_segmentado'].sum())\n",
    "\n",
    "# *********** CREACIÓN DEL GRÁFICO ************************\n",
    "\n",
    "# crear la instancia del gráfico \n",
    "chrt_merge_sitios_loc_prio_y_pop_fem_ge50 = merge_sitios_loc_prio_y_pop_fem_ge50.plot(\n",
    "    kind='bar', title='Sitios en locs. prioritarias con pob. femenina >= 50%', figsize=(20,5), xlabel='Edo. de la República Mexicana', ylabel='No. de sitios prioritarios', color=['#691C32', '#BC955C']\n",
    ")\n",
    "\n",
    "# añadir los valores a las columnas\n",
    "for x in chrt_merge_sitios_loc_prio_y_pop_fem_ge50.containers:\n",
    "    chrt_merge_sitios_loc_prio_y_pop_fem_ge50.bar_label(x)\n",
    "\n",
    "# cambiar el tamaño de la fuente del las etiquetas de las barras del eje x\n",
    "chrt_merge_sitios_loc_prio_y_pop_fem_ge50.set_xticklabels(labels=merge_sitios_loc_prio_y_pop_fem_ge50['acronimo'], fontsize=10)\n",
    "\n",
    "# cambiar las leyendas \n",
    "new_leyends = [\n",
    "    f'Sitios en locs. prioritarias y pob. fem >= 50% ({ttl_merge_sitios_loc_prio_y_pop_fem_ge50_original} sitios) ORIGINAL',\n",
    "    f'Sitios en locs. prioritarias y pob. fem >= 50% ({ttl_merge_sitios_loc_prio_y_pop_fem_ge50_segmentado} sitios) SEGMENTADO']\n",
    "chrt_merge_sitios_loc_prio_y_pop_fem_ge50.legend(new_leyends, loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del chrt_merge_sitios_loc_prio_y_pop_fem_ge50, sitios_loc_prio_y_pop_fem_ge50_origin, sitios_loc_prio_y_pop_fem_ge50_segment, merge_sitios_loc_prio_y_pop_fem_ge50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_longitud('-99.19822')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
